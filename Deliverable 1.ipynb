{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b98f5c87",
   "metadata": {},
   "source": [
    "## Deliverable 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f0f123",
   "metadata": {},
   "source": [
    "Student ID's:\n",
    "\n",
    "Andreea Roica: 20250361\n",
    "\n",
    "Beatriz Varela: 20250367\n",
    "\n",
    "Barbara Franco: 20250388\n",
    "\n",
    "Marisa Esteves: 20250348"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7c34c",
   "metadata": {},
   "source": [
    "We will follow the CRISP-DM methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b8e299",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747418ed",
   "metadata": {},
   "source": [
    "The goal of this project is to create a regression model that can predict car prices based on its details. This includes:\n",
    "\n",
    "- Regression Benchmarking\n",
    "- Model Optimization\n",
    "- Additional Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e2463",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc350d",
   "metadata": {},
   "source": [
    "Metadata:\n",
    "\n",
    "- **carID** : An attribute that contains an identifier for each car.\n",
    "- **Brand** : The car’s main brand (e.g. Ford, Toyota).\n",
    "- **model** : The car model.\n",
    "- **year**: The year of Registration of the Car.\n",
    "- **transmission** - Type of transmission of the car (e.g. Manual, Automatic, Semi-Automatic)\n",
    "- **mileage** : The total reported distance travelled by the car (in miles).\n",
    "- **tax** : The amount of road tax (in £) that, in 2020, was applicable to the car in question.\n",
    "- **fuelType** : Type of Fuel used by the car (Diesel, Petrol, Hybrid, Electric).\n",
    "- **mpg** : Average Miles per Gallon.\n",
    "- **engineSize** : Size of Engine in liters (Cubic Decimeters).\n",
    "- **paintQuality%** : The mechanic’s assessment of the cars’ overall paint quality and hull integrity (filled by the mechanic during evaluation).\n",
    "- **previousOwners** : Number of previous registered owners of the vehicle.\n",
    "- **hasDamage** : Boolean marker filled by the seller at the time of registration stating whether the car is damaged or not.\n",
    "- **price** : The car’s price when purchased by Cars 4 You (in £)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import openpyxl \n",
    "from math import ceil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import fuzzywuzzy to correct the typos in 'Brand', 'fuelType' snd 'transmission'\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Import get_close_matches to identify and group similar words for typo correction in 'model'\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# Import to perform the Chi-squared test\n",
    "from scipy.stats import chi2_contingency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bcb4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1668f9-5a85-4fc4-a3e0-4f62dfe01344",
   "metadata": {},
   "source": [
    "### Characteristics of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb880c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfb40a0",
   "metadata": {},
   "source": [
    "We can already see that we have Null Values (at least in tax) and have strange values like negative previous owners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4536764-9a60-4e9c-92a9-cb7bed722808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279a0b3c-0252-4172-98eb-3f4ab69279fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232afb71",
   "metadata": {},
   "source": [
    "Identified Problems:\n",
    "\n",
    "- Year and previousOwners is float when it should be integer\n",
    "- hasDamage should be boolean instead of float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287d06cb-66f5-4e24-a24e-25141e2f6062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2f34ee-35d4-4466-b304-789d3830b96c",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0bdd70-99e3-4827-97b1-2d13502d6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Check duplicates:')\n",
    "print(f'Train: {df_train.duplicated().sum()}\\nTest: {df_test.duplicated().sum()}')\n",
    "print('\\nCheck duplicates in carId:')\n",
    "print(f'Train: {df_train.duplicated(subset='carID').sum()}\\nTest: {df_test.duplicated(subset='carID').sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752c90b",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b444907",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Brand', 'model', 'transmission', 'fuelType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c992011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8758aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in categorical_features:\n",
    "    print(f'{feat} :' )\n",
    "    print(f'{pd.concat([df_train[feat], df_test[feat]]).unique().tolist()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb3f70",
   "metadata": {},
   "source": [
    "**Histograms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0041cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    2, \n",
    "    ceil(len(categorical_features) / 2), \n",
    "    figsize=(20, 11)\n",
    "    )\n",
    "\n",
    "for ax, feat in zip(axes.flatten(), categorical_features):\n",
    "    sns.countplot(x=df_train[feat], ax=ax, \n",
    "                  order=df_train[feat].value_counts().index, color = 'hotpink') \n",
    "    ax.set_title(feat)\n",
    "    ax.tick_params(axis='x', rotation=90)  # roda os labels no eixo x\n",
    "\n",
    "\n",
    "plt.suptitle(\"Categorical Variables' Absolute Counts\", fontsize=25)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387de214",
   "metadata": {},
   "source": [
    "With these plots we can visualize the problems in the categorical variables, the huge amount of classes, most with very low frequency and simillar names. We will fix this in Data Preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b041b2",
   "metadata": {},
   "source": [
    "**Association between variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5036f107",
   "metadata": {},
   "source": [
    "To evaluate the association between categorical (nominal) variables we will perfom the chi-squared test. \n",
    "\n",
    "H0: There is no evidence of a statistically significant association.\n",
    "\n",
    "H1: There is a statistically significant association between the variables.\n",
    "\n",
    "Interpretation:\n",
    "- if p_value < 0.05 (significance level): Reject H0, so there is a statistically significant association between the {var1} and {var2}.\n",
    "- if p_value >= 0.05 (significance level): Do not reject H0, so there is no evidence of a statistically significant association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec17ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "association_results = pd.DataFrame(columns=categorical_features, index=categorical_features)\n",
    "\n",
    "def color_pvalues(val):\n",
    "\n",
    "    #Apllies color coding to p-values.\n",
    "    #Green: p-values < 0.05 (significant association).\n",
    "    #Red: p-values >= 0.05 (no significant association).\n",
    "\n",
    "    if val < 0.05:\n",
    "        return 'background-color: lightgreen; color:black; border: 1px solid black;'\n",
    "    else:\n",
    "        return 'background-color: lightcoral; color:black; border: 1px solid black;'\n",
    "\n",
    "for var1 in categorical_features:\n",
    "    for var2 in categorical_features:\n",
    "        #Chi-square test between {var1} and {var2}\n",
    "\n",
    "        contingency_table = pd.crosstab(df_train[var1], df_train[var2]) # Create the contingency table\n",
    "        result = chi2_contingency(contingency_table) # Perform the Chi-square test\n",
    "                                                    #Chi-square Statistic: result[0]\n",
    "                                                    #p-value: result[1]\n",
    "                                                    #Degrees of Freedom: result[2]\n",
    "                                                    #Expected Frequencies: result[3]\n",
    "        association_results.loc[var1, var2] = result[1]\n",
    "\n",
    "association_results= association_results.style.applymap(color_pvalues)\n",
    "display(association_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5100d8",
   "metadata": {},
   "source": [
    "To measure their association we will use Cramer's V (suitable for nominal variables).\n",
    "\n",
    "**Cramer's V = √(X2/N) / min(C-1, R-1)**\n",
    "\n",
    "X2- Chi- squared statistics;\n",
    "\n",
    "N- Total number of observations;\n",
    "\n",
    "C- Number of columns in the contingency table;\n",
    "\n",
    "R- Number of rows in the contingency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1787706",
   "metadata": {},
   "outputs": [],
   "source": [
    "cramer_v_table = pd.DataFrame(columns=categorical_features, index = categorical_features)\n",
    "\n",
    "for var1 in cramer_v_table.columns:\n",
    "    for var2 in cramer_v_table.index:\n",
    "\n",
    "        contingency_table = pd.crosstab(df_train[var1], df_train[var2])\n",
    "        result = chi2_contingency(contingency_table)        \n",
    "\n",
    "        # Calculate Cramer's V\n",
    "        X2 = result[0]\n",
    "        n = df_train.shape[0]\n",
    "        minimum_dimension = min(df_train[var1].nunique(), df_train[var2].nunique())-1\n",
    "        cramer_v_table.loc[var1, var2] = np.sqrt((X2/n) / minimum_dimension)\n",
    "\n",
    "def color_cramervalues(val):\n",
    "    if val > 0.6:\n",
    "        return 'background-color: lightgreen; color:black; border: 1px solid black;'\n",
    "    else:\n",
    "        return 'background-color: lightcoral; color:black; border: 1px solid black;'\n",
    "\n",
    "\n",
    "cramer_v_table= cramer_v_table.style.applymap(color_cramervalues)\n",
    "display(cramer_v_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c23c570",
   "metadata": {},
   "source": [
    "The strength of the associations is low due to the number of typos that exist. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c1e413",
   "metadata": {},
   "source": [
    "### Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e49c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.set_index ('carID')\n",
    "df_test = df_test.set_index ('carID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eacca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = df_train.columns.drop(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6aa107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25907a0",
   "metadata": {},
   "source": [
    "**Histograms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9590604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will put all the numeric variables' histograms in one figure\n",
    "# Prepare figure. Create individual axes where each histogram will be placed\n",
    "fig, axes = plt.subplots(2, ceil(len(numeric_features) / 2 ), figsize = (20, 11))\n",
    "\n",
    "for ax, feat in zip(axes.flatten(), numeric_features):\n",
    "    ax.hist(df_train[feat], color = 'hotpink')\n",
    "    ax.set_title(feat, y = -0.13)\n",
    "\n",
    "# Delete empty plots\n",
    "for ax in axes.flatten()[len(numeric_features):]:\n",
    "    ax.axis('off')  \n",
    "\n",
    "# Add a centered title to the figure:\n",
    "plt.suptitle(\"Numeric Variables' Histograms\", fontsize=25)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab11239a",
   "metadata": {},
   "source": [
    "**Boxplots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will put all the numeric variables' histograms in one figure\n",
    "# Prepare figure. Create individual axes where each histogram will be placed\n",
    "fig, axes = plt.subplots(2, ceil(len(numeric_features) / 2 ), figsize = (20, 11))\n",
    "\n",
    "for ax, feat in zip(axes.flatten(), numeric_features):\n",
    "    sns.boxplot(x=df_train[feat], ax=ax, color='hotpink')\n",
    "\n",
    "# Delete empty plots\n",
    "for ax in axes.flatten()[len(numeric_features):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "# Add a centered title to the figure:\n",
    "plt.suptitle(\"Numeric Variables' Box Plots\", fontsize=25)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba9da6",
   "metadata": {},
   "source": [
    "paintQuality% and hasDamage appear to be the only features without outliers. hasDamage is a straight line only since it only has 0 ou NA.\n",
    "\n",
    "The remaining features have a lot of outliers, and very extreme ones since the distribuition is very compressed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f62dd6e",
   "metadata": {},
   "source": [
    "**Correlations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51517255",
   "metadata": {},
   "source": [
    "To measure the correlation between numerical variables we decided to use Spearman's coefficient, as it captures monotonic associations, not just linear ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_train[numeric_features].corr(method=\"spearman\")\n",
    "corr = corr.round(2)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86d186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare figure\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "mask_annot = np.absolute(corr.values) >= 0.5 \n",
    "annot = np.where(mask_annot, corr.values, np.full(corr.shape,\"\")) \n",
    "\n",
    "\n",
    "# Plot heatmap of the correlation matrix\n",
    "sns.heatmap(data=corr, \n",
    "            annot=annot, # Specify custom annotation\n",
    "            fmt='s', # The annotation matrix now has strings, so we need to explicitly say this\n",
    "            vmin=-1, vmax=1, \n",
    "            center=0, # Center the colormap at zero\n",
    "            square=True, # Make each cell square-shaped\n",
    "            linewidths=.5, # Add lines between cells\n",
    "            cmap='PiYG' # Diverging color map\n",
    "            )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982ab95",
   "metadata": {},
   "source": [
    "'previousOwners' and 'paintQuality%' present almost no correlation with the remainder, which indicates some degree of irrelevance.\n",
    "\n",
    "'mileage' and 'year' show strong correlation (in opposite directions).\n",
    "\n",
    "'mpg' and 'tax' show medium correlation (in opposite directions).\n",
    "\n",
    "'mpg' and 'year', 'tax' and 'mileage', 'tax' and 'year' show medium-low correlation.\n",
    "\n",
    "The value of the correlations is probably affected by the amount of existing errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e323c2",
   "metadata": {},
   "source": [
    "**Bivariate plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98265db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f70b762",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1e99a4",
   "metadata": {},
   "source": [
    "### Hold Out Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdbca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_train['price']\n",
    "data = df_train.drop(['price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8bc05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data, \n",
    "                                                 target, \n",
    "                                                 test_size=0.2, \n",
    "                                                 random_state=15, \n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b8990-ad2a-4247-a5fd-1c87b1991882",
   "metadata": {},
   "source": [
    "### Categorical Variables Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e64eea1-567d-47fc-920b-0d86230721c3",
   "metadata": {},
   "source": [
    "##### *Brands*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217999db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre processing the data set to be easier to find clusters:\n",
    "    #remove spaces (at the beginning and end) and lowercase all letters\n",
    "df_train['Brand'] = df_train['Brand'].where(df_train['Brand'].isna(), df_train['Brand'].astype(str).str.strip().str.upper())\n",
    "\n",
    " #does not replace NaN's\n",
    "df_test['Brand']  = df_test['Brand'].where(df_test['Brand'].isna(), df_test['Brand'].astype(str).str.strip().str.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4910a425-f1bd-4647-8ad8-bf1b25bc093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = pd.concat([df_train['Brand'], df_test['Brand']]).dropna().unique().tolist()\n",
    "print(f' Typos in brands: {brands}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc979f5b",
   "metadata": {},
   "source": [
    "In Brands we have the value 'W' which could mean VW or BMW. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4002fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_brand_w(df, brand, model):\n",
    "\n",
    "    '''\n",
    "    The function will switch the observations 'w' and 'W' with 'BMW' and 'VW' depending on the correspondence of their\n",
    "    models in other observations. This function is only applied to one element, one brand and the corresponding model\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        the DataFrame whose columns are to be fixed\n",
    "        \n",
    "    brand : string\n",
    "        the brand \n",
    "\n",
    "    model : string\n",
    "        the corresponding model\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    brand : string\n",
    "        correct model, which will be 'BMW' or 'VW' if the brand is 'w' or 'W', and the input brand otherwise\n",
    "    \n",
    "\n",
    "    '''\n",
    "\n",
    "    # If the brand in lower case is 'w' and its a string\n",
    "    if isinstance(brand, str) and brand.lower() == 'w':\n",
    "\n",
    "        # For cicle to go over the brands and corresponding models in the DataFrame\n",
    "        for brand_in_column, model_in_column in zip(df['Brand'], df['model']):\n",
    "\n",
    "            # If the same model is found, then return the corresponding brand\n",
    "            if isinstance(brand_in_column, str) and model_in_column == model and brand_in_column.lower() != 'w':\n",
    "                print (brand_in_column)\n",
    "                return brand_in_column\n",
    "            \n",
    "    # If the brand is not 'w' or 'W', it remains the same           \n",
    "    return brand\n",
    "\n",
    "# Correct the 'w' and 'W' values in the columns 'Brand' by applying the function correct_brand_w to all elements in the column\n",
    "df_train['Brand'] = df_train.apply(lambda row: correct_brand_w(df_train, row['Brand'], row['model']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Brand'] = df_test.apply(lambda row: correct_brand_w(df_test, row['Brand'], row['model']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09611ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[(df_train['Brand']=='w') | (df_train['Brand']=='W')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75588f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[(df_test['Brand']=='w') | (df_test['Brand']=='W')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adf33e5",
   "metadata": {},
   "source": [
    "We can see that we fixed the problem with the brand 'w' except for the cases with null values, which are only 5 observations. The ones that were fixed were all 'VW' so we will assume the same for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd859418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[\n",
    "    df_train['Brand'] =='W' ,\n",
    "    'Brand'\n",
    "] = 'VW'\n",
    "\n",
    "df_train[df_train['Brand'] =='W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72552e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[\n",
    "    df_test['Brand'] =='W' ,\n",
    "    'Brand'\n",
    "] = 'VW'\n",
    "\n",
    "df_test[df_test['Brand'] =='W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8fbfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = pd.concat([df_train['Brand'], df_test['Brand']]).dropna().unique().tolist()\n",
    "print(f' Typos in brands: {brands}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c57f1-48a7-4424-8359-237d7f089eff",
   "metadata": {},
   "source": [
    "TheFuzz uses the Levenshtein edit distance to calculate the degree of closeness between two strings.\n",
    "\n",
    "**Levenshtein distance** = at a minimum, how many edits are required to change one string into the other.\n",
    "\n",
    "[https://www.datacamp.com/tutorial/fuzzy-string-python]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b565a1-2699-44b5-9cd8-0fe32ed7c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([len(brand) for brand in brands])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763d9e5b-9213-4525-b4ae-bf4919191a9f",
   "metadata": {},
   "source": [
    "[https://stackoverflow.com/questions/31806695/when-to-use-which-fuzz-function-to-compare-2-strings]\n",
    "\n",
    "[https://medium.com/@laxmi17sarki/string-matching-using-fuzzywuzzy-24be9e85c88d]\n",
    "\n",
    "**Ratio choice**: fuzz.WRatio, most robust method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebb4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Creates clusters with similar brands\n",
    "def create_clusters(brand_list, column, threshold=86): #groups strings with a similarity greater than or equal to treshold%. \n",
    "    clusters = []\n",
    "    for brand in brand_list:\n",
    "        found = False\n",
    "        for cluster in clusters:\n",
    "            # evaluates if brand is similar to any cluster\n",
    "            if any(fuzz.WRatio(str(brand).lower(), str(b).lower()) >= threshold for b in cluster):\n",
    "                cluster.append(brand)\n",
    "                found = True\n",
    "                break\n",
    "        #if it doesn't find a match --> new cluster\n",
    "        if not found:\n",
    "            clusters.append([brand])\n",
    "\n",
    "    # Gives the clusters names- chooses the most freq name\n",
    "    mapping = {}\n",
    "    counts = df_train[column].value_counts()\n",
    "    for cluster in clusters:\n",
    "        mode = max(cluster, key=lambda x: counts.get(x,0))  #finds the \"max\" in the cluster according to the key --> mode\n",
    "        for brand in cluster:\n",
    "            mapping[brand] = str(mode.upper())\n",
    "\n",
    "    return clusters, mapping\n",
    "\n",
    "clusters, mapping = create_clusters(brands, 'Brand', threshold=85)\n",
    "\n",
    "print(\"Clusters:\")\n",
    "for c in clusters:\n",
    "    print(c)\n",
    "\n",
    "df_train['Brand_cleaned'] = df_train['Brand'].map(mapping)\n",
    "df_test['Brand_cleaned'] = df_test['Brand'].map(mapping)\n",
    "\n",
    "print(\"\\nCleaned brand - Train:\")\n",
    "print(df_train['Brand_cleaned'].dropna().unique())\n",
    "\n",
    "print(\"\\nCleaned brand - Test:\")\n",
    "print(df_test['Brand_cleaned'].dropna().unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eb0567-e9e9-4cfc-963f-5ba2a7f51b74",
   "metadata": {},
   "source": [
    "#### *Models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279303aa-9aec-4f9d-b694-daeed6dde26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre processing the data set to be easier to find clusters:\n",
    "    #remove spaces (at the beginning and end) and lowercase all letters\n",
    "df_train['model'] = df_train['model'].where(df_train['model'].isna(), df_train['model'].astype(str).str.strip().str.upper())\n",
    "\n",
    " #does not replace NaN's\n",
    "df_test['model']  = df_test['model'].where(df_test['model'].isna(), df_test['model'].astype(str).str.strip().str.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd810207-5c8c-4e95-b6f0-94068be3fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models= pd.concat([df_train['model'], df_test['model']]).dropna().unique().tolist()\n",
    "print(f'Nº of unique values: {len(models)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2aef80-6dd8-467c-8782-184ff2b2acbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([len(str(model)) for model in models])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837dd19e",
   "metadata": {},
   "source": [
    "Fuzzywuzzy wasnt able to group the same models in the column 'model', so for this case we will use get_close_matches from difflib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d53e24-ad66-4869-bdf2-32b6461a8c44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def similar_models(models):\n",
    "\n",
    "    # This list, which starts as an empty list, will store the similar groups of strings\n",
    "    similar_groups = []\n",
    "    \n",
    "    # Start a for loop that will go over all the values in models\n",
    "    for model in models:\n",
    "\n",
    "        # Transform de list of lists in a unique list with all the values in the sublists\n",
    "        similar_groups_flat = [item for sublist in similar_groups if sublist is not None for item in sublist]\n",
    "\n",
    "        if model in similar_groups_flat:\n",
    "\n",
    "            # If the model is already in similar_groups_flat, then it already has its similarity group, no need to serach for more\n",
    "            continue\n",
    "        else:\n",
    "             \n",
    "             # Calculate the similarity between model and the other observations and keep the ones with a similarity higher than 0.85\n",
    "             close_matches = get_close_matches(model, models, cutoff=0.85)\n",
    "\n",
    "             model_prefix =  model.split(\" \")[0] \n",
    "             \n",
    "             # For the models with more than one word it is necessary to evaluate the prefix in order to separate them well\n",
    "             if \" \" in model:\n",
    "\n",
    "                # Only keep the models with the same model code/ prefix. Different model codes belong to different models\n",
    "                close_matches = [match for match in close_matches if match.split(\" \")[0] == model_prefix]\n",
    "\n",
    "            # Add the close matches to the list of similar groups\n",
    "             similar_groups.append(close_matches)\n",
    "\n",
    "    return similar_groups\n",
    "\n",
    "clusters = similar_models (models)\n",
    "\n",
    "print(\"Clusters:\")\n",
    "for c in clusters:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca38fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_column_model(model, similar_groups):\n",
    "\n",
    "    # If the element is NA or an empty string then nothing is changed\n",
    "    if pd.isna(model) or model == ' ':\n",
    "        return model\n",
    "    \n",
    "    # If the model has only one character then it is not possible to associate it with any model so return NA\n",
    "    elif len(model) == 1:\n",
    "        return np.nan\n",
    "    \n",
    "    # Put the model in upper case and remove spaces in beggining or end of the string\n",
    "    model = model.upper().strip()\n",
    "\n",
    "    # Go over all the sublists in similar_groups, the word similarity groups\n",
    "    for group in similar_groups:\n",
    "\n",
    "        # Find the group which contains model\n",
    "        if model in group :\n",
    "\n",
    "            # Return the match that is the longest, since it will be the complete one ( in our data set we dont have typos because of more characters, it is always beacause of less)\n",
    "            return max(group, key=len) \n",
    "        \n",
    "    return model\n",
    "\n",
    "df_train['model_cleaned'] = df_train['model'].apply(lambda x: correct_column_model(x, clusters))\n",
    "df_test['model_cleaned'] =  df_test['model'].apply(lambda x: correct_column_model(x, clusters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nCleaned model - Train:\")\n",
    "print(df_train['model_cleaned'].dropna().unique())\n",
    "\n",
    "print(\"\\nCleaned model - Test:\")\n",
    "print(df_test['model_cleaned'].dropna().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16001a9a-38c0-450e-bb03-a60194dc0a54",
   "metadata": {},
   "source": [
    "#### *Fuel Types*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre processing the data set to be easier to find clusters:\n",
    "    #remove spaces (at the beginning and end) and lowercase all letters\n",
    "df_train['fuelType'] = df_train['fuelType'].where(df_train['fuelType'].isna(), df_train['fuelType'].astype(str).str.strip().str.upper().str.replace('[\\s\\-]+', '_', regex=True))\n",
    "\n",
    " #does not replace NaN's\n",
    "df_test['fuelType']  = df_test['fuelType'].where(df_test['fuelType'].isna(), df_test['fuelType'].astype(str).str.strip().str.upper().str.replace('[\\s\\-]+', '_', regex=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc7cae-93fc-4d0d-bedd-b64fbfb8823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_types=pd.concat([df_train['fuelType'], df_test['fuelType']]).dropna().unique().tolist()\n",
    "print(f' Typos in models: {fuel_types}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1722143e-0f8c-475b-a32f-3562b33e7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates clusters with similar fuel types\n",
    "clusters, mapping = create_clusters(fuel_types, 'fuelType', threshold=85)\n",
    "\n",
    "df_train['fuelType_cleaned'] = df_train['fuelType'].map(mapping)\n",
    "df_test['fuelType_cleaned'] = df_test['fuelType'].map(mapping)\n",
    "\n",
    "print(\"Clusters:\")\n",
    "for c in clusters:\n",
    "    print(c)\n",
    "\n",
    "print(\"\\nCleaned fuel type - Train:\")\n",
    "print(df_train['fuelType_cleaned'].dropna().unique())\n",
    "\n",
    "print(\"\\nCleaned fuel type - Test:\")\n",
    "print(df_test['fuelType_cleaned'].dropna().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd1f06b-e968-48d0-bb26-3eb9a634bfa8",
   "metadata": {},
   "source": [
    "#### *Transmission*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac5f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre processing the data set to be easier to find clusters:\n",
    "    #remove spaces (at the beginning and end) and lowercase all letters\n",
    "df_train['transmission'] = df_train['transmission'].where(df_train['transmission'].isna(), df_train['transmission'].astype(str).str.strip().str.upper())\n",
    "\n",
    " #does not replace NaN's\n",
    "df_test['transmission']  = df_test['transmission'].where(df_test['transmission'].isna(), df_test['transmission'].astype(str).str.strip().str.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09322ac-a8ee-4389-94a0-5d3ed088711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_types = pd.concat([df_train['transmission'], df_test['transmission']]).dropna().unique().tolist()\n",
    "print(f' Typos in models: {transmission_types}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e13d8-fad7-4c05-84a2-5cb49cd4d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates clusters with similar fuel types\n",
    "clusters, mapping = create_clusters(transmission_types, 'transmission', threshold=86)\n",
    "\n",
    "df_train['transmission_cleaned'] = df_train['transmission'].map(mapping)\n",
    "df_test['transmission_cleaned'] = df_test['transmission'].map(mapping)\n",
    "\n",
    "print(\"Clusters:\")\n",
    "for c in clusters:\n",
    "    print(c)\n",
    "\n",
    "print(\"\\nCleaned transmission - Train:\")\n",
    "print(df_train['transmission_cleaned'].dropna().unique())\n",
    "\n",
    "print(\"\\nCleaned transmission - Test:\")\n",
    "print(df_test['transmission_cleaned'].dropna().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6750f793",
   "metadata": {},
   "source": [
    "### Numerical Variables Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82daeb6",
   "metadata": {},
   "source": [
    "Bea --- Eliminar as inválidas, adicionar as percentagens , etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a3736",
   "metadata": {},
   "source": [
    "### Outlier Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1efec5",
   "metadata": {},
   "source": [
    "### New Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c26528-7efc-42fa-b7d1-1e023f82a019",
   "metadata": {},
   "source": [
    "### Missing Values Treatment and Typecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace074ac-1e4d-47f1-aefb-3b5c5ebaddb3",
   "metadata": {},
   "source": [
    "NaNs will be treated as a new category.\n",
    "\n",
    "Let's analyze the zeros vs. the NaNs to see if the NaNs are associated with damaged or undamaged cars.:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e982e79-64b8-44e8-a03b-ad058e108115",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Brand_cleaned','model','fuelType_cleaned','transmission_cleaned', 'year']\n",
    "distinctive_cols = [ 'price', 'mileage', 'tax', 'paintQuality%', 'previousOwners', 'hasDamage']\n",
    "\n",
    "df_train_temp = df_train.dropna(subset=cols) [cols + distinctive_cols] \n",
    "                                            #selectes the rows with no NaN's in cols \n",
    "df_train_temp = df_train_temp [ df_train_temp.duplicated(subset=cols, keep=False) ].sort_values(cols) \n",
    "                                            #saves the filtered duplicates\n",
    "groups_filtered = df_train_temp.groupby(cols).filter(lambda group: group['hasDamage'].eq(0).any() and group['hasDamage'].isna().any())\n",
    "                                            #groups the rows by cols\n",
    "                                            #.filter: function applied to the groups created by groupby\n",
    "                                            #saves the group if there is at least one obs with 0 damamge and another with nan damage\n",
    "group_dict = {name: group for name, group in groups_filtered.groupby(cols)} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0009ab9f-1b84-4b09-8f7e-0b77757679db",
   "metadata": {},
   "source": [
    "*Note*: groups_filtered.groupby(cols) is a GroupBy object. Saves the name (brand, model, etc.) of the group and the observations in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704d881-f033-43cf-affa-c7af2f5b5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of groups: {len(group_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze the tendecy of the price, mileage, tax and paintQuality% in the groups with missing hasDamage\n",
    "diffs_list = []\n",
    "\n",
    "for name, group in group_dict.items():\n",
    "    zeros = group[group['hasDamage'] == 0]\n",
    "    nans = group[group['hasDamage'].isna()]\n",
    "\n",
    "    if zeros.empty or nans.empty:\n",
    "            continue\n",
    "\n",
    "    diffs = {col: zeros[col].mean() - nans[col].mean() for col in ['price', 'mileage', 'tax', 'paintQuality%', 'previousOwners']}\n",
    "    diffs_list.append(diffs)\n",
    "\n",
    "diffs_df = pd.DataFrame(diffs_list)\n",
    "    \n",
    "diffs_df.median().to_frame(name='mean_diff') #median of all differences "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc1ebee-c407-4ba8-8ffa-48b4fa425520",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "We decided NaN's will be **damaged cars?**. Now lets correct the data type of the variable:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61971078-6b75-4567-a144-db1a7d9c67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct data type:\n",
    "df_train['hasDamage'] = df_train ['hasDamage'].astype(bool)\n",
    "df_train[df_train['hasDamage'].isna()] ['hasDamage'] = True\n",
    "df_test['hasDamage'] = df_test ['hasDamage'].astype(bool)\n",
    "df_test[df_test['hasDamage'].isna()] ['hasDamage'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccc32c3-c9d9-48e1-8e05-26d0dd293da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data type:\n",
    "df_train.hasDamage.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a4fa7-e964-48d6-95e0-d07e7c5cbb45",
   "metadata": {},
   "source": [
    "#### *previousOwners*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a50c9-1ba3-42f7-aa13-998aaeae4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'% of observations with negative owners:\\nTrain:{round(df_train[df_train['previousOwners']<0].shape[0] / df_train.shape[0], 5)}\\nTest:{round(df_test[df_test['previousOwners']<0].shape[0] / df_test.shape[0], 5)}')\n",
    "print(f'\\n% of observations with 0 owners:\\nTrain:{round(df_train[df_train['previousOwners']==0].shape[0] / df_train.shape[0], 5)}\\nTest:{round(df_test[df_test['previousOwners']==0].shape[0] / df_test.shape[0], 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9ca10-05d5-4f13-b3f3-82903b18e017",
   "metadata": {},
   "source": [
    "Invalid observations - Positives vs Negatives: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2062ecf-21f3-4c6a-89d9-8aa2e9ce4ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_owners = df_train[df_train['previousOwners']<0]\n",
    "pos_owners = df_train[df_train['previousOwners']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40318bcc-bec9-4444-8b56-610b134b39c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_owners.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b930e2-7e83-4c4a-9e89-afb39cc49779",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_owners.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb18cb7-b119-4903-a403-4e3ae16d939d",
   "metadata": {},
   "source": [
    "Comparing the positives with the negatives:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d39713-ed62-4e76-ba29-a2d95033ef42",
   "metadata": {},
   "source": [
    "##### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa27911-57d6-4506-8619-c2d5a700b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['OwnerStatus'] = np.where(df_train['previousOwners'] > 0, 1, 0)\n",
    "    #1 if previousOwners>0 , 0 if previousOwners<=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80af3c-d295-4ea1-a683-283436d63fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Brand_cleaned', 'model','fuelType_cleaned', 'transmission_cleaned', 'hasDamage']\n",
    "not_used=['Brand', 'transmission', 'fuelType', 'model_cleaned', 'previousOwners', 'OwnerStatus']\n",
    "numeric_features = df_train.columns.drop(categorical_features + not_used)\n",
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907093cf-e8b7-40a4-adea-651bfa4b37cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_temp = df_train[df_train['previousOwners']!=0]\n",
    "\n",
    "#Numeric Variables\n",
    "for col in numeric_features:\n",
    "    if col not in df_train.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    df_train_temp.boxplot(column=col, by='OwnerStatus', grid=False)\n",
    "    plt.title(f\"{col} by OwnerStatus\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"OwnerStatus (0=Negative, 1=Positive)\")\n",
    "    plt.ylabel(col)\n",
    "    plt.xticks([1, 2], ['Negative', 'Positive'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#Categorical Variables\n",
    "for col in categorical_features:\n",
    "    if col not in df_train.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    pd.crosstab(df_train['OwnerStatus'], df_train[col], normalize='index').plot(\n",
    "        kind='bar', stacked=True, ax=plt.gca(), colormap='tab20'\n",
    "    )\n",
    "    plt.title(f\"Distribution of {col} by OwnerStatus\")\n",
    "    plt.xlabel(\"OwnerStatus (0=Negative, 1=Positive)\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.legend(title=col, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "df_train.drop('OwnerStatus', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d825e4d5-5868-4b11-8292-eb983e0925e7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Negatives and positives exhibit similar behavior in almost all features, except for tax and engine size, where the difference is quite significant.\n",
    "\n",
    "Therefore, the population of positives and negatives cannot be equated.\n",
    "\n",
    "We will treat *negatives* and *zeros* as NaNs. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a51cf0-ad05-4afd-b683-faf643927adb",
   "metadata": {},
   "source": [
    "#### *paintQuality%*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6964f895-48b4-485e-b030-ec2d03b6c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'% of observations outside of a meaningful range: {round(df_train[df_train['paintQuality%']>100].shape[0] / df_train.shape[0], 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b873d-50d2-4afe-b0dd-9aaefdf774b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train [df_train ['paintQuality%']>100] ['paintQuality%'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe1926-365b-4651-80e7-c84fce564b5a",
   "metadata": {},
   "source": [
    "##### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a19af3f-91aa-4cda-8453-3a38894018bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PaintQualityStatus'] = np.where(df_train['paintQuality%'] <= 100, 1, 0)\n",
    "    #1 if paintQuality%<=100 , 0 if paintQuality%>100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e2ee3-be91-4ba2-aec8-822d9591a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Brand_cleaned', 'model','fuelType_cleaned', 'transmission_cleaned', 'hasDamage']\n",
    "not_used=['Brand', 'transmission', 'fuelType', 'model_cleaned', 'paintQuality%', 'PaintQualityStatus']\n",
    "numeric_features = df_train.columns.drop(categorical_features + not_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f6a33-ce32-4445-a40d-b06f9be514a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Numeric Variables\n",
    "for col in numeric_features:\n",
    "    if col not in df_train.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    df_train.boxplot(column=col, by='PaintQualityStatus', grid=False)\n",
    "    plt.title(f\"{col} by PaintQualityStatus\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"PaintQualityStatus (0=Not Valid, 1=Valid)\")\n",
    "    plt.ylabel(col)\n",
    "    plt.xticks([1, 2], ['Negative', 'Positive'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#Categorical Variables\n",
    "for col in categorical_features:\n",
    "    if col not in df_train.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    pd.crosstab(df_train['PaintQualityStatus'], df_train[col], normalize='index').plot(\n",
    "        kind='bar', stacked=True, ax=plt.gca(), colormap='tab20'\n",
    "    )\n",
    "    plt.title(f\"Distribution of {col} by PaintQualityStatus\")\n",
    "    plt.xlabel(\"PaintQualityStatus (0=Not Valid, 1=Valid)\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.legend(title=col, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd20350-189e-4f87-a61e-f4dcc4e8d011",
   "metadata": {},
   "source": [
    "Looking at the box plots and histograms, there is no apparent reason for these invalid observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca37a61-afa9-459a-8aa5-d592dcebf00c",
   "metadata": {},
   "source": [
    "##### Let us analyze these observations in more detail: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01034918-4352-4d69-b65a-7447df897c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average paint quality by brand\n",
    "df_train.groupby('Brand_cleaned')['paintQuality%'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac1907f-1e1f-4ef0-a5da-b5281d98d56d",
   "metadata": {},
   "source": [
    "No brand stands out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2b56e-bad0-426a-bdf9-0342d7928de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Already seen in the histogram, but just to confirm.\n",
    "print('Of the invalid observations, how many are in each brand (in %):\\n')\n",
    "print(df_train[df_train['PaintQualityStatus'] == 0]['Brand_cleaned'].value_counts(normalize=True).sort_values(ascending=False))\n",
    "print('\\nOf the valid observations, how many are in each brand (in %):\\n')\n",
    "print(df_train[df_train['PaintQualityStatus'] == 1]['Brand_cleaned'].value_counts(normalize=True).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234006a2-f433-49e2-982c-a36009f3f8ca",
   "metadata": {},
   "source": [
    "We confirm the distribution is very similar. \n",
    "\n",
    "Let's compare the Ford group in both data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a69d7-c0ff-4b13-bd53-d7696d5ac858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_temp = df_train[df_train['Brand_cleaned']=='Ford']\n",
    "\n",
    "#Numeric Variables\n",
    "for col in numeric_features:\n",
    "    if col not in df_train_temp.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    df_train_temp.boxplot(column=col, by='PaintQualityStatus', grid=False)\n",
    "    plt.title(f\"{col} by PaintQualityStatus - Ford Group\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"PaintQualityStatus (0=Not Valid, 1=Valid)\")\n",
    "    plt.ylabel(col)\n",
    "    plt.xticks([1, 2], ['Negative', 'Positive'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#Categorical Variables\n",
    "for col in categorical_features:\n",
    "    if col not in df_train_temp.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    pd.crosstab(df_train_temp['PaintQualityStatus'], df_train_temp[col], normalize='index').plot(\n",
    "        kind='bar', stacked=True, ax=plt.gca(), colormap='tab20'\n",
    "    )\n",
    "    plt.title(f\"Distribution of {col} by PaintQualityStatus- Ford Group\")\n",
    "    plt.xlabel(\"PaintQualityStatus (0=Not Valid, 1=Valid)\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.legend(title=col, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e22212a-3f8a-44c8-9bbd-da0cbcf21545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('PaintQualityStatus', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd90f57a-3abb-418c-aff0-88ffc1893823",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "I would consider the invalid observations as NaN's. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b22a9-a708-43af-bd50-5dcc1d46629c",
   "metadata": {},
   "source": [
    "#### *engineSize*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8841a-31e9-429b-b402-284fb9a2494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'% of negative sizes: {round(df_train[df_train['engineSize']<0].shape[0] / df_train.shape[0], 5)}')\n",
    "print(f'% of size 0: {round(df_train[df_train['engineSize']==0].shape[0] / df_train.shape[0], 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb206ba-be2b-4610-b725-ffbc55ef5b2d",
   "metadata": {},
   "source": [
    "Comparing the positives with the negatives:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49554596-e7d0-42dc-a1d5-10625f20c551",
   "metadata": {},
   "source": [
    "##### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33766dc9-eed5-4ee0-ab0f-5d54754f2b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['EngineSizeStatus'] = np.where(df_train['engineSize'] >= 0, 1, 0)\n",
    "    #1 if valid , 0 if invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5006ca-cdc4-42d2-8b2d-5aa471f72e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Brand_cleaned', 'model','fuelType_cleaned', 'transmission_cleaned', 'hasDamage']\n",
    "not_used=['Brand', 'transmission', 'fuelType', 'model_cleaned', 'engineSize', 'EngineSizeStatus']\n",
    "numeric_features = df_train.columns.drop(categorical_features + not_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed098b-74c9-4ff3-985b-c27e75379e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_temp = df_train[df_train['engineSize']!=0]\n",
    "\n",
    "#Numeric Variables\n",
    "for col in numeric_features:\n",
    "    if col not in df_train_temp.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    df_train_temp.boxplot(column=col, by='EngineSizeStatus', grid=False)\n",
    "    plt.title(f\"{col} by EngineSizeStatus\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"EngineSizeStatus (0=Negative, 1=Positive)\")\n",
    "    plt.ylabel(col)\n",
    "    plt.xticks([1, 2], ['Negative', 'Positive'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#Categorical Variables\n",
    "for col in categorical_features:\n",
    "    if col not in df_train_temp.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    pd.crosstab(df_train_temp['EngineSizeStatus'], df_train_temp[col], normalize='index').plot(\n",
    "        kind='bar', stacked=True, ax=plt.gca(), colormap='tab20'\n",
    "    )\n",
    "    plt.title(f\"Distribution of {col} by EngineSizeStatus\")\n",
    "    plt.xlabel(\"EngineSizeStatus (0=Negative, 1=Positive)\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.legend(title=col, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "df_train.drop('EngineSizeStatus', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea9f6bf-1843-4eaf-96bd-babccb9849f5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "The negatives and positives show similar behavior. Should we do the correspondence?\n",
    "\n",
    "Treat the zeros as NaN's.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d781e-bc23-40be-8afb-fe0961243b60",
   "metadata": {},
   "source": [
    "#### *mpg*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23161040-1ca2-408b-85d4-3aca9e452e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'% of negative mpg: {round(df_train[df_train['mpg']<0].shape[0] / df_train.shape[0], 5)}')\n",
    "print(f'% of 0 mpg: {round(df_train[df_train['mpg']==0].shape[0] / df_train.shape[0], 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c295fa-5d04-40f7-8ce7-acbd8fcde2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'% of observations outside of meaningful interval (10-70)- Train: {round(df_train[(df_train['mpg']<10) & (df_train['mpg']>70)].shape[0] / df_train.shape[0], 5)}')\n",
    "print(f'% of observations outside of meaningful interval (10-70)- Test: {round(df_test[(df_test['mpg']<10) & (df_test['mpg']>70)].shape[0] / df_test.shape[0], 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fa2586-1b76-4f6b-9be1-48edfaeb0267",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "No observations outside the range [10, 70].\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b74e82-6950-418d-a9d2-c1ad6d1ae6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change mpg of Eletrics to Unknown:\n",
    "df_train.loc[df_train['fuelType']=='Electric', 'fuelType'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2118f1df-3d7d-4604-b1b2-d90bbf69a8ad",
   "metadata": {},
   "source": [
    "Comparing the positives with the negatives:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6fc206-f5e0-4eae-9ef2-207bcd083677",
   "metadata": {},
   "source": [
    "##### Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2494797-504a-4352-b6a6-6c24901013d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['mpgStatus'] = np.where(df_train['mpg'] >= 0, 1, 0)\n",
    "    #1 if valid , 0 if invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d87e2bb-c030-4825-862c-46bc64ab5a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Brand_cleaned', 'model','fuelType_cleaned', 'transmission_cleaned', 'hasDamage']\n",
    "not_used=['Brand', 'transmission', 'fuelType', 'model_cleaned', 'mpg', 'mpgStatus']\n",
    "numeric_features = df_train.columns.drop(categorical_features + not_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380a91f0-dd16-4218-a150-15045ba41556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Numeric Variables\n",
    "for col in numeric_features:\n",
    "    if col not in df_train.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    df_train.boxplot(column=col, by='mpgStatus', grid=False)\n",
    "    plt.title(f\"{col} by mpgStatus\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"mpgStatus (0=Negative, 1=Positive)\")\n",
    "    plt.ylabel(col)\n",
    "    plt.xticks([1, 2], ['Negative', 'Positive'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#Categorical Variables\n",
    "for col in categorical_features:\n",
    "    if col not in df_train.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    pd.crosstab(df_train['mpgStatus'], df_train[col], normalize='index').plot(\n",
    "        kind='bar', stacked=True, ax=plt.gca(), colormap='tab20'\n",
    "    )\n",
    "    plt.title(f\"Distribution of {col} by mpgStatus\")\n",
    "    plt.xlabel(\"mpgStatus (0=Negative, 1=Positive)\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.legend(title=col, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e985d6-b671-4930-ae4e-3d036359ec7a",
   "metadata": {},
   "source": [
    "Clearly not similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89091db4-7f5e-4b78-a7be-75dde6d7ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Of the invalid observations, how many are in each brand (in %):\\n')\n",
    "print(df_train[df_train['mpgStatus'] == 0]['Brand_cleaned'].value_counts(normalize=True).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6259166-5b42-4815-8ba7-559edada3172",
   "metadata": {},
   "source": [
    "Most invalid observations are concentrated in the Ford and Mercedes group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73f7b1-364a-4906-8c68-6543fa55aa26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_temp = df_train[df_train['Brand_cleaned']=='Ford']\n",
    "#Numeric Variables\n",
    "for col in numeric_features:\n",
    "    if col not in df_train_temp.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    df_train_temp.boxplot(column=col, by='mpgStatus', grid=False)\n",
    "    plt.title(f\"{col} by mpgStatus- Ford Group\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"mpgStatus (0=Negative, 1=Positive)\")\n",
    "    plt.ylabel(col)\n",
    "    plt.xticks([1, 2], ['Negative', 'Positive'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#Categorical Variables\n",
    "for col in categorical_features:\n",
    "    if col not in df_train.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    pd.crosstab(df_train_temp['mpgStatus'], df_train_temp[col], normalize='index').plot(\n",
    "        kind='bar', stacked=True, ax=plt.gca(), colormap='tab20'\n",
    "    )\n",
    "    plt.title(f\"Distribution of {col} by mpgStatus - Ford Group\")\n",
    "    plt.xlabel(\"mpgStatus (0=Negative, 1=Positive)\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.legend(title=col, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a971c43-24b2-43da-ba3a-5631dd073f1a",
   "metadata": {},
   "source": [
    "**FORD GROUP**\n",
    "\n",
    "The range of years is greater for invalid observations, and their average price and mileage is slightly higher.\n",
    "\n",
    "The invalid observations are concentrated in some specfic models--> check again after cleaning the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a59b35-178f-4915-918d-d961e5d8f40e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_temp = df_train[df_train['Brand_cleaned']=='Mercedes']\n",
    "#Numeric Variables\n",
    "for col in numeric_features:\n",
    "    if col not in df_train_temp.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    df_train_temp.boxplot(column=col, by='mpgStatus', grid=False)\n",
    "    plt.title(f\"{col} by mpgStatus- Mercedes Group\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"mpgStatus (0=Negative, 1=Positive)\")\n",
    "    plt.ylabel(col)\n",
    "    plt.xticks([1, 2], ['Negative', 'Positive'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#Categorical Variables\n",
    "for col in categorical_features:\n",
    "    if col not in df_train.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    pd.crosstab(df_train_temp['mpgStatus'], df_train_temp[col], normalize='index').plot(\n",
    "        kind='bar', stacked=True, ax=plt.gca(), colormap='tab20'\n",
    "    )\n",
    "    plt.title(f\"Distribution of {col} by mpgStatus - Mercedes Group\")\n",
    "    plt.xlabel(\"mpgStatus (0=Negative, 1=Positive)\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.legend(title=col, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0808339-4e23-44e8-8ce5-528bc86514aa",
   "metadata": {},
   "source": [
    "**MERCEDES GROUP**\n",
    "\n",
    "The invalid observations are concentrated in some specfic models--> check again after cleaning the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39fa379-1bb1-4c18-b7c2-35c708eb0fa8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "The best thing is to consider the invalid observations as NaN's. \n",
    "\n",
    "Or (after cleaning the models) try to find the correspondence of these observations with the model group.\n",
    "\n",
    "But for the other brands just treat them as NaN's?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19019565-ca46-4323-a803-d06d298ff47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('mpgStatus', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa444b-e968-4e50-9c9a-221943d79518",
   "metadata": {},
   "source": [
    "#### *tax*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807c75c-8b15-49ba-8c52-3e1f7fd8e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'% of negative tax: {round(df_train[df_train['tax']<0].shape[0] / df_train.shape[0], 5)}')\n",
    "print(f'% of 0 tax: {round(df_train[df_train['tax']==0].shape[0] / df_train.shape[0], 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4d07a-cf44-4f4b-a7f0-5f50f0f98d2e",
   "metadata": {},
   "source": [
    "Comparing the positives with the negatives:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a6e82a-dbb9-4b86-944e-3f4e4773e79e",
   "metadata": {},
   "source": [
    "##### Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c639b2-602d-4f01-93bd-8ea1ce6ecd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['taxStatus'] = np.where(df_train['tax'] >= 0, 1, 0)\n",
    "    #1 if valid , 0 if invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56deab01-b834-4c37-b834-90faf31c0ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Brand_cleaned', 'model','fuelType_cleaned', 'transmission_cleaned', 'hasDamage']\n",
    "not_used=['Brand', 'transmission', 'fuelType', 'model_cleaned', 'tax', 'taxStatus']\n",
    "numeric_features = df_train.columns.drop(categorical_features + not_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b489fd-a0ff-47ee-9879-aa5332e90e8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_temp = df_train[df_train['tax']!=0]\n",
    "\n",
    "#Numeric Variables\n",
    "for col in numeric_features:\n",
    "    if col not in df_train_temp.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    df_train_temp.boxplot(column=col, by='taxStatus', grid=False)\n",
    "    plt.title(f\"{col} by taxStatus\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"taxStatus (0=Negative, 1=Positive)\")\n",
    "    plt.ylabel(col)\n",
    "    plt.xticks([1, 2], ['Negative', 'Positive'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#Categorical Variables\n",
    "for col in categorical_features:\n",
    "    if col not in df_train_temp.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    pd.crosstab(df_train_temp['taxStatus'], df_train_temp[col], normalize='index').plot(\n",
    "        kind='bar', stacked=True, ax=plt.gca(), colormap='tab20'\n",
    "    )\n",
    "    plt.title(f\"Distribution of {col} by taxStatus\")\n",
    "    plt.xlabel(\"taxStatus (0=Negative, 1=Positive)\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.legend(title=col, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "df_train.drop('taxStatus', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c073d6a1-0166-4d9f-85a5-7853c215309e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Too different. Treat negatives and 0's as NaN's.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f6491-c299-4df9-b53f-56012fd25e57",
   "metadata": {},
   "source": [
    "#### *mileage*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e74ded4-fbe8-492f-be45-df06daa1e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'% of negative mileage: {round(df_train[df_train['mileage']<0].shape[0] / df_train.shape[0], 5)}')\n",
    "print(f'% of 0 mileage: {round(df_train[df_train['mileage']==0].shape[0] / df_train.shape[0], 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3a423f-cccc-4dd2-b51a-74707088483e",
   "metadata": {},
   "source": [
    "Comparing the positives with the negatives:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffcbe12-0ca2-4c73-96f3-7fa4f11959cf",
   "metadata": {},
   "source": [
    "##### Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758eff9-6934-478f-8d59-67649e56df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['mileageStatus'] = np.where(df_train['tax'] >= 0, 1, 0)\n",
    "    #1 if valid , 0 if invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1814aeac-d1b1-46fd-855f-edf86d3b50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Brand_cleaned', 'model','fuelType_cleaned', 'transmission_cleaned', 'hasDamage']\n",
    "not_used=['Brand', 'transmission', 'fuelType', 'model_cleaned', 'mileage', 'mileageStatus']\n",
    "numeric_features = df_train.columns.drop(categorical_features + not_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43212eb4-3037-4757-a81b-fa97e5e406dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_temp = df_train[df_train['mileage']!=0]\n",
    "\n",
    "#Numeric Variables\n",
    "for col in numeric_features:\n",
    "    if col not in df_train_temp.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    df_train_temp.boxplot(column=col, by='mileageStatus', grid=False)\n",
    "    plt.title(f\"{col} by mileageStatus\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"mileageStatus (0=Negative, 1=Positive)\")\n",
    "    plt.ylabel(col)\n",
    "    plt.xticks([1, 2], ['Negative', 'Positive'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#Categorical Variables\n",
    "for col in categorical_features:\n",
    "    if col not in df_train_temp.columns:\n",
    "        continue\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    pd.crosstab(df_train_temp['mileageStatus'], df_train_temp[col], normalize='index').plot(\n",
    "        kind='bar', stacked=True, ax=plt.gca(), colormap='tab20'\n",
    "    )\n",
    "    plt.title(f\"Distribution of {col} by mileageStatus\")\n",
    "    plt.xlabel(\"mileageStatus (0=Negative, 1=Positive)\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.legend(title=col, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "df_train.drop('mileageStatus', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808eebf9-c107-4e08-ad30-90a17ae7fcbb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Too different. Treat negatives as NaN's.\n",
    "\n",
    "Are these errors related to the errors in tax and mpg?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b7e1a-5265-4d0c-8f68-d42e7b970513",
   "metadata": {},
   "source": [
    "#### *year*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef84ac30-05fa-44a0-b4da-753b2a5fde27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dbcc5d-45bd-4edf-93a7-48d3fe443081",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['year']==1970]\n",
    "#these observations are outliers and the second does not make sense (automatic and year=1970) --> drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a4a21-e862-4e71-9c32-f7dc7555ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['year']!=1970]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f440a6-4f80-4c83-b946-c5c7399d3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50639ee3",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12853ce3",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0634170b",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e3576",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
