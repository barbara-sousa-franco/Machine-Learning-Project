{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "badc007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_function_TodasCategorias import *\n",
    "from functions_MARISA import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf18f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions_MARISA.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "334eb522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, ElasticNet, HuberRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error, median_absolute_error, root_mean_squared_error\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import TargetEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5d1ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "665d8ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.set_index('carID', inplace=True)\n",
    "df_test.set_index('carID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2441abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d69aa7",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca9ac63",
   "metadata": {},
   "source": [
    "We start by defining the inconsistent values discussed in the EDA as NA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca0536e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['year']>2020, 'year'] = np.nan\n",
    "df_test.loc[df_test['year']>2020, 'year'] = np.nan\n",
    "\n",
    "df_train.loc[df_train['mileage']<0, 'mileage'] = np.nan\n",
    "df_test.loc[df_test['mileage']<0, 'mileage'] = np.nan\n",
    "\n",
    "df_train.loc[df_train['tax']<0, 'tax'] = np.nan\n",
    "df_test.loc[df_test['tax']<0,'tax'] = np.nan\n",
    "\n",
    "df_train.loc[df_train['mpg']<=0, 'mpg'] = np.nan\n",
    "df_test.loc[df_test['mpg']<=0, 'mpg'] = np.nan\n",
    "\n",
    "df_train.loc[df_train['paintQuality%']>100, 'paintQuality%'] = np.nan\n",
    "df_test.loc[df_test['paintQuality%']>100, 'paintQuality%'] = np.nan\n",
    "\n",
    "df_train.loc[df_train['previousOwners']< 0, 'previousOwners'] = np.nan\n",
    "df_test.loc[df_test['previousOwners']< 0, 'previousOwners'] = np.nan\n",
    "\n",
    "df_train.loc[df_train['engineSize']<= 0, 'engineSize'] = np.nan\n",
    "df_test.loc[df_test['engineSize']<= 0, 'engineSize'] = np.nan\n",
    "\n",
    "df_train.loc[df_train['mpg'] < 40, 'mpg'] = np.nan\n",
    "df_train.loc[df_train['engineSize'] < 1, 'engineSize'] = np.nan\n",
    "\n",
    "df_test.loc[df_test['mpg'] < 40, 'mpg'] = np.nan\n",
    "df_test.loc[df_test['engineSize'] < 1, 'engineSize'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec345109",
   "metadata": {},
   "source": [
    "We proceed to round 'year' and 'previousOwners' to whole numbers using the floor function. Other numerical features are rounded to 2 decimal points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80085750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['year'] = np.floor(df_train['year'])\n",
    "df_train['previousOwners'] = np.floor(df_train['previousOwners'])\n",
    "\n",
    "df_test['year'] = np.floor(df_test['year'])\n",
    "df_test['previousOwners'] = np.floor(df_test['previousOwners'])\n",
    "\n",
    "for feat in ['mileage', 'tax', 'mpg', 'engineSize', 'paintQuality%']:\n",
    "    df_train[feat] = df_train[feat].round(2)\n",
    "    df_test[feat] = df_test[feat].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf0b21",
   "metadata": {},
   "source": [
    "We also pre-process the categorical variables in order to have a uniform format for later treatment (inside k-fold CV). We remove leeading and trailing spaces and uppercase all letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "454801c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre processing the categorical variables to be easier to find clusters in typos:\n",
    "    # remove spaces (at the beginning and end) and uppercase all letters\n",
    "    # does not replace NaN's\n",
    "df_train['Brand'] = df_train['Brand'].where(df_train['Brand'].isna(), df_train['Brand'].astype(str).str.strip().str.upper())\n",
    "df_test['Brand']  = df_test['Brand'].where(df_test['Brand'].isna(), df_test['Brand'].astype(str).str.strip().str.upper())\n",
    "\n",
    "df_train['model'] = df_train['model'].where(df_train['model'].isna(), df_train['model'].astype(str).str.strip().str.upper())\n",
    "df_test['model']  = df_test['model'].where(df_test['model'].isna(), df_test['model'].astype(str).str.strip().str.upper())\n",
    "\n",
    "df_train['fuelType'] = df_train['fuelType'].where(df_train['fuelType'].isna(), df_train['fuelType'].astype(str).str.strip().str.upper())\n",
    "df_test['fuelType']  = df_test['fuelType'].where(df_test['fuelType'].isna(), df_test['fuelType'].astype(str).str.strip().str.upper())\n",
    "\n",
    "df_train['transmission'] = df_train['transmission'].where(df_train['transmission'].isna(), df_train['transmission'].astype(str).str.strip().str.upper())\n",
    "df_test['transmission']  = df_test['transmission'].where(df_test['transmission'].isna(), df_test['transmission'].astype(str).str.strip().str.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3225b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = df_train['price']\n",
    "X = df_train.drop('price', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af4260",
   "metadata": {},
   "source": [
    "Notas sobre as classes:\n",
    "\n",
    "- variáveis criadas na inicialização não acabam em _; as ue são criadas dentro dos métodos acabam em _!\n",
    "- criando uma var nos métodos, se ela não começar em self. não será reconhecida por toda a classe, será apenas local!\n",
    "- logo, iniciar com self. para criar novos atributos gerais (assim transform() cconsegue aceder ao atributo criado em fit() por exemplo)\n",
    "- cuidado com data leakage! :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543515b8",
   "metadata": {},
   "source": [
    "### Categorical_Correction Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f5bf759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Categorical_Correction(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):  # initialize the transformer\n",
    "        pass             # self it's how Python refers to the transformer within the class.\n",
    "                         # self.something --> something its an attribute of the transformer.\n",
    "\n",
    "    def fit(self, X, y=None): # fit is where we learn from the data\n",
    "        \"\"\" Learns parameters from train data to then use in categorical variable correction inside \n",
    "        transformer function of this same class.\"\"\"\n",
    "\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        \n",
    "        ###### -----------------------------------------------------BRAND----------------------------------------------------------------------######\n",
    "\n",
    "        self.brands_ = X['Brand'].dropna().unique().tolist()\n",
    "\n",
    "        _, self.mapping_brand_ = create_clusters(X, self.brands_, 'Brand')\n",
    "\n",
    "        ######---------------------------------------------------TRANSMISSION--------------------------------------------------------------------######\n",
    "\n",
    "        self.transmission_types_ = X['transmission'].dropna().unique().tolist()\n",
    "\n",
    "        _, self.mapping_transmission_ = create_clusters(X, self.transmission_types_, 'transmission')\n",
    "\n",
    "\n",
    "        ######----------------------------------------------------FUEL TYPE--------------------------------------------------------------------######\n",
    "\n",
    "        self.fuel_types_= X['fuelType'].dropna().unique().tolist()\n",
    "\n",
    "        _, self.mapping_fueltype_ = create_clusters(X, self.fuel_types_, 'fuelType')\n",
    "\n",
    "\n",
    "        ######------------------------------------------------------MODELS----------------------------------------------------------------------######\n",
    "\n",
    "        self.models_= X['model'].dropna().unique().tolist()\n",
    "\n",
    "        ## Fuzzywuzzy wasn't able to group the same models in the column 'model', so for this case we will use get_close_matches from the difflib library.\n",
    "        self.clusters_ = similar_models(self.models_)\n",
    "\n",
    "        # Calculate counts once before the function\n",
    "        self.model_counts_ = X['model'].value_counts().to_dict()\n",
    "\n",
    "        # List to store the most frequent model in each cluster which will be considered the correct one\n",
    "        self.correct_models_ = []\n",
    "\n",
    "        #   Dictionary to map each model to its correct version\n",
    "        self.model_mapping_ = {}\n",
    "\n",
    "        # For loop to go over all the clusters \n",
    "        for group in self.clusters_:\n",
    "\n",
    "            # The best model of each cluster will be the one with the highest count in the train set, it will be added to the correct_models list\n",
    "            best = max(group, key=lambda x: self.model_counts_.get(x, 0))\n",
    "            self.correct_models_.append(best)\n",
    "\n",
    "            # Map all models in the group to the best model\n",
    "            for model in group:\n",
    "                self.model_mapping_[model] = best\n",
    "\n",
    "        return self\n",
    "    \n",
    "\n",
    "\n",
    "    def transform(self, X): # transform is where we apply the learned parameters to correct the data\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        # BRAND----------------------------------------------------------------------------------------------\n",
    "\n",
    "        # We first correct the 'W' brands which should be either VW or BMW\n",
    "        # this correction does not depent on params learned from train data:\n",
    "        X['Brand'] = X.apply(lambda row: correct_brand_w(X, row['Brand'], row['model']),axis=1)\n",
    "        # for cars with no model where correct_brand_w doesn't work:\n",
    "        X.loc[X['Brand'] =='W' ,'Brand'] = 'VW'\n",
    "\n",
    "        # Remaining typos:\n",
    "        X['Brand_cleaned'] = X['Brand'].apply(lambda x: correct_categorical(self.mapping_brand_, x))\n",
    "\n",
    "        # TRANSMISSION---------------------------------------------------------------------------------------\n",
    "        X['transmission_cleaned'] = X['transmission'].apply(lambda x: correct_categorical(self.mapping_transmission_, x))\n",
    "\n",
    "\n",
    "        # FUELTYPE -------------------------------------------------------------------------------------------\n",
    "        X['fuelType_cleaned'] = X['fuelType'].apply(lambda x: correct_categorical(self.mapping_fueltype_, x))\n",
    "\n",
    "\n",
    "        # MODEL ---------------------------------------------------------------------------------------------\n",
    "        X['model_cleaned'] = X['model'].apply(lambda x: correct_column_model(self.correct_models_, self.model_mapping_, x, self.clusters_))\n",
    "\n",
    "\n",
    "        # Finally, we drop the variables with typos:\n",
    "        X = X.drop(['Brand', 'model', 'transmission', 'fuelType'], axis=1)\n",
    "\n",
    "\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa71397d",
   "metadata": {},
   "source": [
    "### Outlier_Treatment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8f2bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Outlier_Treatment(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, dim=3, ratio = 0.00008):\n",
    "        self.feat_lst = ['tax', 'mileage', 'mpg', 'engineSize', 'year', 'paintQuality%', 'previousOwners']\n",
    "        self.dim = dim\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        self.outlier_limits_ = {}\n",
    "        self.quantiles_ = {}\n",
    "\n",
    "        for feat in self.feat_lst:\n",
    "            Q1 = X[feat].quantile(0.25)\n",
    "            Q3 = X[feat].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            self.outlier_limits_[feat] = (Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)\n",
    "            self.quantiles_[feat] = (X[feat].quantile(0.01),X[feat].quantile(0.99))\n",
    "            \n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        outlier_counts = pd.Series(0, index=X.index)\n",
    "\n",
    "        for feat in self.feat_lst:\n",
    "\n",
    "            upper = self.outlier_limits_[feat][1]\n",
    "            lower = self.outlier_limits_[feat][0]\n",
    "\n",
    "            # counting in how many feats each point is an outlier \n",
    "            #outlier_counts += ((X[feat] < lower) | (X[feat] >  upper)).astype(int)\n",
    "\n",
    "\n",
    "            if X[X[feat] > upper].shape[0]/ X.shape[0] >= self.ratio:\n",
    "                X.loc[X[feat] > upper, feat] = self.quantiles_[feat][1]\n",
    "\n",
    "            if X[X[feat] < lower].shape[0]/ X.shape[0] >= self.ratio:\n",
    "                X.loc[X[feat] < lower, feat] = self.quantiles_[feat][0]\n",
    "\n",
    "\n",
    "        return X\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534fa42e",
   "metadata": {},
   "source": [
    "### Missing_Value_Treatment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "590b727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Missing_Value_Treatment(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "\n",
    "        # Missing BRAND ---------------------------------------------------------------------------------\n",
    "        self.brand_mode_ = X['Brand_cleaned'].mode().iloc[0]\n",
    "        self.model_to_brand_ = (X.dropna(subset=['Brand_cleaned', 'model_cleaned'])\n",
    "                            .groupby('model_cleaned')['Brand_cleaned']\n",
    "                            .agg(lambda x: x.mode().iloc[0])  # get most frequent brand for each model\n",
    "                            .to_dict())\n",
    "\n",
    "        # Missing MODEL ---------------------------------------------------------------------------------\n",
    "        self.model_maps_ = build_model_mappings(X)\n",
    "\n",
    "        # Missing YEAR ---------------------------------------------------------------------------------\n",
    "        self.bins_ = X['mileage'].quantile([0, 0.2, 0.4, 0.6, 0.8, 1]).values\n",
    "        self.labels_ = ['very low', 'low', 'average', 'high', 'very high']\n",
    "        self.year_median_ = X['year'].median()\n",
    "\n",
    "        X['mileage_bin'] = pd.cut(X['mileage'], bins=self.bins_, labels=self.labels_, include_lowest=True)\n",
    "\n",
    "        self.year_map_mileage_ = (X.dropna(subset=['year', 'mileage_bin']).groupby('mileage_bin', observed=False)['year'].median().to_dict())\n",
    "\n",
    "        self.year_map_tax_ = (X.dropna(subset=['year', 'tax']).groupby('tax', observed=False)['year'].median().to_dict())\n",
    "\n",
    "        self.year_map_mpg_ = (X.dropna(subset=['year', 'mpg']).groupby('mpg', observed=False)['year'].median().to_dict())\n",
    "\n",
    "        # Missing MILEAGE ---------------------------------------------------------------------------------\n",
    "        self.mileage_map_ = (X.dropna(subset=['mileage','year']).groupby(['year'])['mileage'].median().to_dict())\n",
    "\n",
    "        # Missing TAX --------------------------------------------------------------------------------\n",
    "        self.tax_maps_ = build_tax_mappings(X)\n",
    "\n",
    "        # Missing FUELTYPE --------------------------------------------------------------------------------\n",
    "        self.fueltype_maps_ = build_fuel_mappings(X)\n",
    "\n",
    "        # Missing MPG -----------------------------------------------------------------------------------------\n",
    "        self.mpg_maps_ = build_mpg_mappings(X)\n",
    "\n",
    "        # Missing ENGINE SIZE --------------------------------------------------------------------------------\n",
    "        self.enginesize_maps_ = build_engine_mappings(X)\n",
    "\n",
    "        # Missing PAINTQUALITY% --------------------------------------------------------------------------------\n",
    "        self.paint_maps_ = build_paint_mappings(X)\n",
    "\n",
    "        # Missing PREVIOUS OWNERS --------------------------------------------------------------------------------\n",
    "        self.previous_owners_maps_ = build_owners_mappings(X)\n",
    "\n",
    "        # Missing TRANSMISSION --------------------------------------------------------------------------------\n",
    "        self.transmission_maps_ = build_transmission_mappings(X)\n",
    "\n",
    "        # Missing HASDAMAGE --------------------------------------------------------------------------------\n",
    "        # We just replace NaN values with True in transform()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        if 'mileage_bin' in X.columns:\n",
    "            X = X.drop('mileage_bin', axis=1)\n",
    "\n",
    "        # Missing BRAND --------------------------------------------------------------------------------\n",
    "        X['Brand_cleaned'] = X.apply(lambda row: impute_brand(row, self.model_to_brand_, self.brand_mode_),axis=1)\n",
    "\n",
    "        # Missing MODEL --------------------------------------------------------------------------------\n",
    "        X['model_cleaned'] = X.apply(lambda row: impute_model_flexible(row, self.model_maps_),axis=1)\n",
    "\n",
    "        # Missing YEAR --------------------------------------------------------------------------------\n",
    "        X['mileage_bin'] = pd.cut(X['mileage'], bins=self.bins_, labels=self.labels_, include_lowest=True)\n",
    "\n",
    "        X['year'] = X.apply(lambda row: impute_year(row, self.year_map_mileage_, self.year_map_tax_, self.year_map_mpg_, self.year_median_),axis=1)\n",
    "\n",
    "        X = X.drop('mileage_bin', axis= 1)\n",
    "\n",
    "        # Missing MILEAGE --------------------------------------------------------------------------------\n",
    "        X['mileage'] = X.apply(lambda row: impute_mileage(row, self.mileage_map_), axis=1)\n",
    "\n",
    "        # Missing TAX --------------------------------------------------------------------------------\n",
    "        X['tax'] = X.apply(lambda row: impute_tax(row, self.tax_maps_), axis=1)\n",
    "\n",
    "        # Missing FUELTYPE --------------------------------------------------------------------------------\n",
    "        X['fuelType_cleaned'] = X.apply(lambda row: impute_fueltype(row, self.fueltype_maps_),axis=1)\n",
    "\n",
    "        # Missing MPG --------------------------------------------------------------------------------\n",
    "        X['mpg'] = X.apply(lambda row: impute_mpg(row, self.mpg_maps_), axis=1)\n",
    "\n",
    "        # Missing ENGINESIZE --------------------------------------------------------------------------------\n",
    "        X['engineSize'] = X.apply(lambda row: impute_engine(row, self.enginesize_maps_), axis=1)\n",
    "\n",
    "        # Missing PAINTQUALITY% --------------------------------------------------------------------------------\n",
    "        X['paintQuality%'] = X.apply(lambda row: impute_paint(row, self.paint_maps_), axis=1)\n",
    "\n",
    "        # Missing PREVIOUS OWNERS --------------------------------------------------------------------------------\n",
    "        X['previousOwners'] = X.apply(lambda row: impute_owners(row, self.previous_owners_maps_), axis=1)\n",
    "\n",
    "        # Missing TRANSMISSION --------------------------------------------------------------------------------\n",
    "        X['transmission_cleaned'] = X.apply(lambda row: impute_transmission(row, self.transmission_maps_),axis=1)\n",
    "\n",
    "        # Missing HASDAMAGE --------------------------------------------------------------------------------\n",
    "        X['hasDamage'] = X['hasDamage'].fillna(True)\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02573c",
   "metadata": {},
   "source": [
    "### Typecasting Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26f8f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Typecasting(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        X['year'] = X['year'].astype(int)\n",
    "        X['previousOwners'] = X['previousOwners'].astype(int)\n",
    "        X['hasDamage'] = X['hasDamage'].astype(bool) \n",
    "        \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0f45da",
   "metadata": {},
   "source": [
    "### Feature_Engineering Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be8a933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Engineering(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        df_temp = X.copy()\n",
    "        df_temp['price'] = y.values\n",
    "        brand_price = df_temp.groupby('Brand_cleaned')['price'].mean().sort_values()\n",
    "        economy_limit = brand_price.quantile(0.33)\n",
    "        semi_premium_limit = brand_price.quantile(0.66)\n",
    "\n",
    "        self.segment_ = {brand: (1 if price <= economy_limit else 2 if price <= semi_premium_limit else 3) for brand, price in brand_price.items()}\n",
    "\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        # Car Age\n",
    "        X['carAge'] = (2020 - X['year']).round(0).astype(int)\n",
    "\n",
    "        # Average Car Usage\n",
    "        X['AvgUsage'] = X['mileage'] / (X['carAge'] +1)\n",
    "\n",
    "        # Car Segment based on Brand\n",
    "        X['carSegment'] = X['Brand_cleaned'].map(self.segment_)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94582e5e",
   "metadata": {},
   "source": [
    "### Encoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a735b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        # features encoded by target encoding:\n",
    "        self.target_features_ = ['model_cleaned','Brand_cleaned']\n",
    "\n",
    "        self.encoder_ = TargetEncoder(categories=\"auto\" , target_type=\"continuous\" ) \n",
    "        self.encoder_.fit(X[self.target_features_], y)\n",
    "\n",
    "        # features encoded by one-hot encoding:\n",
    "        self.one_hot_features_ = ['fuelType_cleaned', 'transmission_cleaned']\n",
    "\n",
    "        self.encoder_fueltype_ = OneHotEncoder(categories=\"auto\" , handle_unknown=\"ignore\", sparse_output=False).set_output(transform='pandas')\n",
    "        self.encoder_fueltype_.fit(X[['fuelType_cleaned']])\n",
    "\n",
    "        self.encoder_transmission_ = OneHotEncoder(categories=\"auto\" , handle_unknown=\"ignore\", sparse_output=False).set_output(transform='pandas')\n",
    "        self.encoder_transmission_.fit(X[['transmission_cleaned']])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        # target\n",
    "        X[[f'{feat}_encoded' for feat in self.target_features_]] = self.encoder_.transform(X[self.target_features_])\n",
    "\n",
    "        # one_hot\n",
    "        self.dummies_fueltype_ = self.encoder_fueltype_.transform(X[['fuelType_cleaned']])\n",
    "        self.dummies_transmission_ = self.encoder_transmission_.transform(X[['transmission_cleaned']])\n",
    "\n",
    "        X = pd.concat([X, self.dummies_fueltype_, self.dummies_transmission_], axis=1)\n",
    "\n",
    "        X = X.drop(['Brand_cleaned', 'transmission_cleaned', 'fuelType_cleaned','model_cleaned'], axis=1)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af33071c",
   "metadata": {},
   "source": [
    "### Scaler Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "627871a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Scaler(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, scaler=StandardScaler()):\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        self.numeric_features_ = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "        \n",
    "        self.scaler.fit(X[self.numeric_features_])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        X = X.copy()\n",
    "        self.feature_names_in_ = X.columns\n",
    "\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        \n",
    "        X[self.numeric_features_] = self.scaler.transform(X[self.numeric_features_])\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2233eb",
   "metadata": {},
   "source": [
    "### Pre-processing complete: stack everything inside pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4cfe46",
   "metadata": {},
   "source": [
    "### Feature_Selection Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cff21c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Selection(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, rfe_options=[8, 10], spearman_options=[0.2, 0.25, 0.3],var_threshold=0.01):\n",
    "\n",
    "        self.rfe_options = rfe_options\n",
    "        self.spearman_options = spearman_options\n",
    "        self.var_threshold = var_threshold\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "\n",
    "        X['hasDamage'] = X['hasDamage'].astype(int)\n",
    "\n",
    "        # From numerical features we keep only the ones with variance != 0 (non-constant)\n",
    "        numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "        non_constant_features = [f for f in numeric_features if X[f].var() > 0]\n",
    "\n",
    "        results = []  # to store all combinations and MAE\n",
    "        mae_scores = []\n",
    "\n",
    "        # Loop over all parameter combinations\n",
    "        for n_feats in self.rfe_options:\n",
    "            for spearman_thr in self.spearman_options:\n",
    "                mae_scores = []\n",
    "\n",
    "                features = [f for f in non_constant_features if X[f].var() > self.var_threshold]\n",
    "\n",
    "                # Compute absolute Spearman correlation with target\n",
    "                features_fold = X[features]\n",
    "                corr_with_target = features_fold.apply(lambda x: x.corr(y, method='spearman'))\n",
    "                selected_spearman = corr_with_target[abs(corr_with_target) > spearman_thr].index.tolist() # each index is a feature\n",
    "                \n",
    "                # Wrapper method: RFE with Linear Regression\n",
    "                model = LinearRegression()\n",
    "                rfe_lr = RFE(estimator=model, n_features_to_select=n_feats)\n",
    "                rfe_lr.fit(X= X[features], y= y)\n",
    "                rfe_lr_features = pd.Series(rfe_lr.support_, index=features)\n",
    "                rfe_lr_features_list = rfe_lr_features[rfe_lr_features].index.tolist() # only chooses the features where RFE selected True\n",
    "\n",
    "                # Wrapper method: RFE with Lasso\n",
    "                model = Lasso()\n",
    "                rfe_l = RFE(estimator=model, n_features_to_select=n_feats)\n",
    "                rfe_l.fit(X= X[features], y= y)\n",
    "                rfe_l_features = pd.Series(rfe_l.support_, index=features)\n",
    "                rfe_l_features_list = rfe_l_features[rfe_l_features].index.tolist()\n",
    "\n",
    "                # Embedded method: Lasso\n",
    "                lasso = LassoCV(cv=3, max_iter=5000)\n",
    "                lasso.fit(X[features], y)\n",
    "                coef = pd.Series(lasso.coef_, index = features)\n",
    "                lasso_features = coef[coef != 0].index.tolist()\n",
    "\n",
    "                # Majority vote: keep features that appear in more than or at least half of the methods\n",
    "                feature_counts = {}\n",
    "                for method in [selected_spearman, rfe_lr_features_list, rfe_l_features_list, lasso_features]:\n",
    "                    for f in method:\n",
    "                        feature_counts[f] = feature_counts.get(f,0)+1\n",
    "                n_methods = len([selected_spearman, rfe_lr_features_list, rfe_l_features_list, lasso_features])\n",
    "                threshold = n_methods//2 + n_methods%2\n",
    "                final_features = [f for f,count in feature_counts.items() if count >= threshold]\n",
    "\n",
    "                # Evaluate performance with selected features\n",
    "                model = LinearRegression()\n",
    "                model.fit(X[final_features], y)\n",
    "                y_pred = model.predict(X[final_features])\n",
    "                mae = mean_absolute_error(y, y_pred)\n",
    "                mae_scores.append(mae)\n",
    "                results.append({'features': final_features, 'mae': mae})\n",
    "\n",
    "        # Select combination with lowest MAE\n",
    "        self.best_ = min(results, key=lambda x: x['mae'])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "        X = X.copy()\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        selected_features = self.best_['features']\n",
    "\n",
    "        X = X[selected_features]\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64034c2d",
   "metadata": {},
   "source": [
    "### PCA Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29202409",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA_class(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__ (self, var_acum=0.90):\n",
    "        self.var_acum = var_acum\n",
    "\n",
    "    def fit (self, X, y=None):\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        pca =PCA(n_components=self.var_acum, svd_solver='full') # svd_solver='full' to use when n_components is float\n",
    "                                                                # when the number of components is a float between 0 and 1, \n",
    "                                                                # it selects the number of components such that the acum var explained is greater than the n_components\n",
    "        pca.fit(X)\n",
    "\n",
    "        # saves the number of components selected and the fiitted pca object\n",
    "        self.n_components_ = pca.n_components_\n",
    "        self.pca_ = pca\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform (self, X):\n",
    "        \n",
    "        X = X.copy()\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        X_pca = self.pca_.transform(X)\n",
    "\n",
    "        # create a DataFrame with the PCA components\n",
    "        pca_columns = [f'PCA_{i+1}' for i in range(self.n_components_)]\n",
    "        X_pca_df = pd.DataFrame(X_pca, columns=pca_columns, index=X.index)\n",
    "\n",
    "        return X_pca_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9732ce2e",
   "metadata": {},
   "source": [
    "### PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc4c7c3",
   "metadata": {},
   "source": [
    "Ao fazer apenas categorial = Categorical Correction(), por exemplo, estamos a criar um objeto, não são aplicadas nenhumas transformações, nem é aprendido nada.\n",
    "\n",
    "Ao fazer categorical.fit(X_train) estamos a aprender os parâmetros.\n",
    "\n",
    "Ao fazer categorical.transform(X_train) são efetivamente feitas as alterações com base nas regras aprendidas em .fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fdfa392",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('categorical treatment', Categorical_Correction()),  #using just feature selection\n",
    "    ('outlier treatment', Outlier_Treatment()),                   \n",
    "    ('missing value treatment', Missing_Value_Treatment()),\n",
    "    ('typecasting', Typecasting()), \n",
    "    ('feature engineering', Feature_Engineering()), \n",
    "    ('encoder', Encoder() ), \n",
    "    ('scaler', Scaler()), \n",
    "    ('feature selection', Feature_Selection()),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42)) \n",
    "])\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('categorical treatment', Categorical_Correction()),  #using just pca\n",
    "    ('outlier treatment', Outlier_Treatment()),                   \n",
    "    ('missing value treatment', Missing_Value_Treatment()),\n",
    "    ('typecasting', Typecasting()), \n",
    "    ('feature engineering', Feature_Engineering()), \n",
    "    ('encoder', Encoder() ), \n",
    "    ('scaler', Scaler()),\n",
    "    ('pca', PCA_class()),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline3 = Pipeline([\n",
    "    ('categorical treatment', Categorical_Correction()),  #using both feature selection and pca\n",
    "    ('outlier treatment', Outlier_Treatment()),                   \n",
    "    ('missing value treatment', Missing_Value_Treatment()),\n",
    "    ('typecasting', Typecasting()), \n",
    "    ('feature engineering', Feature_Engineering()), \n",
    "    ('encoder', Encoder() ), \n",
    "    ('scaler', Scaler()), \n",
    "    ('feature selection', Feature_Selection()),\n",
    "    ('pca', PCA_class()),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e820757",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ada50733",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    \n",
    "    # Maximum depth of the tree\n",
    "    'regressor__max_depth': [3, 5, 10, 20, None], # 'None' means unlimited depth\n",
    "    \n",
    "    # Minimum number of samples required to split an internal node\n",
    "    'regressor__min_samples_split': [3, 5, 10, 20],  \n",
    "    \n",
    "    # Minimum number of samples required to be at a leaf node\n",
    "    'regressor__min_samples_leaf': [2, 3, 5, 10],\n",
    "    \n",
    "    # The function to measure the quality of a split \n",
    "    'regressor__criterion': ['squared_error', 'absolute_error', 'friedman_mse'],  # mae = absolute_error\n",
    "    \n",
    "    # Minimum impurity decrease required for a split to happen\n",
    "    'regressor__min_impurity_decrease': [0.0, 0.0001, 0.001, 0.01],\n",
    "\n",
    "    # The number of features to consider when looking for the best split\n",
    "    'regressor__max_features': [None, 'sqrt', 'log2']\n",
    "    \n",
    "}\n",
    "\n",
    "# Making an adjusted R2 function:\n",
    "\n",
    "def adjusted_r2_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    n, p = X.shape\n",
    "    return 1 - (1 - r2) * (n - 1) / (n - p - 1) # erros\n",
    "\n",
    "adj_r2 = make_scorer(adjusted_r2_scorer, greater_is_better=True) #erros\n",
    "\n",
    "\n",
    "scoring = { 'R2': 'r2', #'AdjR2': adj_r2 -> esta funcao e dificil de implementar, erros\n",
    "    'MAE': 'neg_mean_absolute_error',\n",
    "    'MAPE': 'neg_mean_absolute_percentage_error',\n",
    "    'MedAE': 'neg_median_absolute_error',\n",
    "    'RMSE': 'neg_root_mean_squared_error'}\n",
    "\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline, # estimator is the model to be optimized\n",
    "                        # in this case RandomizedSearchCV will test parameter options for the regressor but performing all the preprocessing steps\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,             \n",
    "    scoring=scoring, # evaluation metrics\n",
    "    refit = 'MAE',\n",
    "    cv=5,                 # 10-fold CV -> mudei para 5 \n",
    "    verbose=2, # to show iterations\n",
    "    return_train_score=True, # to return train metric results in cv_scores_\n",
    "    random_state=random_state, # defined on top of the nb\n",
    "    n_jobs=-1 # to use all cpu cores for faster results\n",
    ")\n",
    "\n",
    "random_search2 = RandomizedSearchCV(\n",
    "    estimator=pipeline2,                 \n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,             \n",
    "    scoring=scoring, \n",
    "    refit = 'MAE',\n",
    "    cv=5,                \n",
    "    verbose=2, \n",
    "    return_train_score=True, \n",
    "    random_state=random_state, \n",
    "    n_jobs=-1 \n",
    ")\n",
    "\n",
    "random_search3 = RandomizedSearchCV(\n",
    "    estimator=pipeline3,                 \n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,             \n",
    "    scoring=scoring, \n",
    "    refit = 'MAE',\n",
    "    cv=5,                \n",
    "    verbose=2, \n",
    "    return_train_score=True, \n",
    "    random_state=random_state, \n",
    "    n_jobs=-1 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1055e41",
   "metadata": {},
   "source": [
    "### Running RnadomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd939715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RandomizedSearchCV with Pipeline...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "RandomizedSearchCV Results:\n",
      "Best parameters: {'regressor__min_samples_split': 10, 'regressor__min_samples_leaf': 3, 'regressor__min_impurity_decrease': 0.001, 'regressor__max_features': 'sqrt', 'regressor__max_depth': 20, 'regressor__criterion': 'absolute_error'}\n",
      "Best CV score: -1824.3819\n"
     ]
    }
   ],
   "source": [
    "print(\"Running RandomizedSearchCV with Pipeline...\")\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(\"\\nRandomizedSearchCV Results:\")\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Best CV score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "\n",
    "#test_score_pipeline = random_search.score(X_test, y_test)\n",
    "#print(f\"Test score: {test_score_pipeline:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0ca741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "metric_cols_train = [c for c in results_df.columns if c.startswith(\"mean_train_\")]\n",
    "std_cols_train = [c for c in results_df.columns if c.startswith(\"std_train_\")]\n",
    "\n",
    "metric_cols_test = [c for c in results_df.columns if c.startswith(\"mean_test_\")]\n",
    "std_cols_test = [c for c in results_df.columns if c.startswith(\"std_test_\")]\n",
    "\n",
    "df_metrics = results_df[[\"params\"] + metric_cols_train + std_cols_train + metric_cols_test + std_cols_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b188c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_R2</th>\n",
       "      <th>mean_train_MAE</th>\n",
       "      <th>mean_train_MAPE</th>\n",
       "      <th>mean_train_MedAE</th>\n",
       "      <th>mean_train_RMSE</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>mean_test_MAE</th>\n",
       "      <th>mean_test_MAPE</th>\n",
       "      <th>mean_test_MedAE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'regressor__min_samples_split': 3, 'regressor...</td>\n",
       "      <td>0.899829</td>\n",
       "      <td>-1687.418622</td>\n",
       "      <td>-0.102923</td>\n",
       "      <td>-1011.809827</td>\n",
       "      <td>-3081.312867</td>\n",
       "      <td>0.873194</td>\n",
       "      <td>-1894.056494</td>\n",
       "      <td>-0.115705</td>\n",
       "      <td>-1133.045593</td>\n",
       "      <td>-3463.051823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'regressor__min_samples_split': 10, 'regresso...</td>\n",
       "      <td>0.735692</td>\n",
       "      <td>-3108.152204</td>\n",
       "      <td>-0.214746</td>\n",
       "      <td>-2136.500000</td>\n",
       "      <td>-5003.310295</td>\n",
       "      <td>0.732508</td>\n",
       "      <td>-3123.075679</td>\n",
       "      <td>-0.216417</td>\n",
       "      <td>-2159.700000</td>\n",
       "      <td>-5031.954895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'regressor__min_samples_split': 10, 'regresso...</td>\n",
       "      <td>0.610624</td>\n",
       "      <td>-3957.427383</td>\n",
       "      <td>-0.286371</td>\n",
       "      <td>-2802.500000</td>\n",
       "      <td>-6075.009678</td>\n",
       "      <td>0.610895</td>\n",
       "      <td>-3962.566211</td>\n",
       "      <td>-0.287248</td>\n",
       "      <td>-2818.350000</td>\n",
       "      <td>-6070.647062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'regressor__min_samples_split': 20, 'regresso...</td>\n",
       "      <td>0.610624</td>\n",
       "      <td>-3957.427383</td>\n",
       "      <td>-0.286371</td>\n",
       "      <td>-2802.500000</td>\n",
       "      <td>-6075.009678</td>\n",
       "      <td>0.610895</td>\n",
       "      <td>-3962.566211</td>\n",
       "      <td>-0.287248</td>\n",
       "      <td>-2818.350000</td>\n",
       "      <td>-6070.647062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'regressor__min_samples_split': 10, 'regresso...</td>\n",
       "      <td>0.910809</td>\n",
       "      <td>-1355.397900</td>\n",
       "      <td>-0.081502</td>\n",
       "      <td>-689.350000</td>\n",
       "      <td>-2907.815093</td>\n",
       "      <td>0.869619</td>\n",
       "      <td>-1824.381912</td>\n",
       "      <td>-0.109647</td>\n",
       "      <td>-1014.150000</td>\n",
       "      <td>-3509.522262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'regressor__min_samples_split': 5, 'regressor...</td>\n",
       "      <td>0.814031</td>\n",
       "      <td>-2638.037607</td>\n",
       "      <td>-0.176657</td>\n",
       "      <td>-1801.861177</td>\n",
       "      <td>-4198.788477</td>\n",
       "      <td>0.810113</td>\n",
       "      <td>-2653.930876</td>\n",
       "      <td>-0.177677</td>\n",
       "      <td>-1804.555509</td>\n",
       "      <td>-4241.228335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'regressor__min_samples_split': 10, 'regresso...</td>\n",
       "      <td>0.881534</td>\n",
       "      <td>-2048.606442</td>\n",
       "      <td>-0.131890</td>\n",
       "      <td>-1378.598240</td>\n",
       "      <td>-3349.698918</td>\n",
       "      <td>0.865654</td>\n",
       "      <td>-2143.470581</td>\n",
       "      <td>-0.138094</td>\n",
       "      <td>-1424.483147</td>\n",
       "      <td>-3567.353047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'regressor__min_samples_split': 10, 'regresso...</td>\n",
       "      <td>0.735692</td>\n",
       "      <td>-3108.152204</td>\n",
       "      <td>-0.214746</td>\n",
       "      <td>-2136.500000</td>\n",
       "      <td>-5003.310295</td>\n",
       "      <td>0.732508</td>\n",
       "      <td>-3123.075679</td>\n",
       "      <td>-0.216417</td>\n",
       "      <td>-2159.700000</td>\n",
       "      <td>-5031.954895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'regressor__min_samples_split': 10, 'regresso...</td>\n",
       "      <td>0.755794</td>\n",
       "      <td>-3156.524188</td>\n",
       "      <td>-0.233600</td>\n",
       "      <td>-2295.724914</td>\n",
       "      <td>-4811.482023</td>\n",
       "      <td>0.751587</td>\n",
       "      <td>-3171.563504</td>\n",
       "      <td>-0.234611</td>\n",
       "      <td>-2316.297436</td>\n",
       "      <td>-4851.229997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'regressor__min_samples_split': 10, 'regresso...</td>\n",
       "      <td>0.862941</td>\n",
       "      <td>-2012.607762</td>\n",
       "      <td>-0.126367</td>\n",
       "      <td>-1247.250000</td>\n",
       "      <td>-3600.726408</td>\n",
       "      <td>0.847054</td>\n",
       "      <td>-2126.974319</td>\n",
       "      <td>-0.132924</td>\n",
       "      <td>-1338.650000</td>\n",
       "      <td>-3803.911474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_train_R2  \\\n",
       "0  {'regressor__min_samples_split': 3, 'regressor...       0.899829   \n",
       "1  {'regressor__min_samples_split': 10, 'regresso...       0.735692   \n",
       "2  {'regressor__min_samples_split': 10, 'regresso...       0.610624   \n",
       "3  {'regressor__min_samples_split': 20, 'regresso...       0.610624   \n",
       "4  {'regressor__min_samples_split': 10, 'regresso...       0.910809   \n",
       "5  {'regressor__min_samples_split': 5, 'regressor...       0.814031   \n",
       "6  {'regressor__min_samples_split': 10, 'regresso...       0.881534   \n",
       "7  {'regressor__min_samples_split': 10, 'regresso...       0.735692   \n",
       "8  {'regressor__min_samples_split': 10, 'regresso...       0.755794   \n",
       "9  {'regressor__min_samples_split': 10, 'regresso...       0.862941   \n",
       "\n",
       "   mean_train_MAE  mean_train_MAPE  mean_train_MedAE  mean_train_RMSE  \\\n",
       "0    -1687.418622        -0.102923      -1011.809827     -3081.312867   \n",
       "1    -3108.152204        -0.214746      -2136.500000     -5003.310295   \n",
       "2    -3957.427383        -0.286371      -2802.500000     -6075.009678   \n",
       "3    -3957.427383        -0.286371      -2802.500000     -6075.009678   \n",
       "4    -1355.397900        -0.081502       -689.350000     -2907.815093   \n",
       "5    -2638.037607        -0.176657      -1801.861177     -4198.788477   \n",
       "6    -2048.606442        -0.131890      -1378.598240     -3349.698918   \n",
       "7    -3108.152204        -0.214746      -2136.500000     -5003.310295   \n",
       "8    -3156.524188        -0.233600      -2295.724914     -4811.482023   \n",
       "9    -2012.607762        -0.126367      -1247.250000     -3600.726408   \n",
       "\n",
       "   mean_test_R2  mean_test_MAE  mean_test_MAPE  mean_test_MedAE  \\\n",
       "0      0.873194   -1894.056494       -0.115705     -1133.045593   \n",
       "1      0.732508   -3123.075679       -0.216417     -2159.700000   \n",
       "2      0.610895   -3962.566211       -0.287248     -2818.350000   \n",
       "3      0.610895   -3962.566211       -0.287248     -2818.350000   \n",
       "4      0.869619   -1824.381912       -0.109647     -1014.150000   \n",
       "5      0.810113   -2653.930876       -0.177677     -1804.555509   \n",
       "6      0.865654   -2143.470581       -0.138094     -1424.483147   \n",
       "7      0.732508   -3123.075679       -0.216417     -2159.700000   \n",
       "8      0.751587   -3171.563504       -0.234611     -2316.297436   \n",
       "9      0.847054   -2126.974319       -0.132924     -1338.650000   \n",
       "\n",
       "   mean_test_RMSE  \n",
       "0    -3463.051823  \n",
       "1    -5031.954895  \n",
       "2    -6070.647062  \n",
       "3    -6070.647062  \n",
       "4    -3509.522262  \n",
       "5    -4241.228335  \n",
       "6    -3567.353047  \n",
       "7    -5031.954895  \n",
       "8    -4851.229997  \n",
       "9    -3803.911474  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics[['params',\n",
    "            'mean_train_R2', 'mean_train_MAE', 'mean_train_MAPE', 'mean_train_MedAE', 'mean_train_RMSE',\n",
    "            'mean_test_R2', 'mean_test_MAE', 'mean_test_MAPE', 'mean_test_MedAE', 'mean_test_RMSE']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7e5f1",
   "metadata": {},
   "source": [
    "Os valores dos scores são negativos, porque internamente o sklearn assume que maior = melhor. Então, para encontrar o melhor (menor) MAE tem de colocar o sinal de menos antes. \n",
    "\n",
    "Medidas onde diz test são referentes aos folds de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3c3fe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m Option 1: -------------------------------------- \u001b[0m \n",
      "\n",
      "regressor__min_samples_split: 3\n",
      "regressor__min_samples_leaf: 10\n",
      "regressor__min_impurity_decrease: 0.0001\n",
      "regressor__max_features: sqrt\n",
      "regressor__max_depth: None\n",
      "regressor__criterion: squared_error\n",
      "\n",
      "    mean_train_R2  mean_train_MAE  mean_train_MAPE  mean_train_MedAE  \\\n",
      "0       0.899829    -1687.418622        -0.102923      -1011.809827   \n",
      "\n",
      "   mean_train_RMSE  mean_test_R2  mean_test_MAE  mean_test_MAPE  \\\n",
      "0     -3081.312867      0.873194   -1894.056494       -0.115705   \n",
      "\n",
      "   mean_test_MedAE  mean_test_RMSE  \n",
      "0     -1133.045593    -3463.051823  \n",
      "\n",
      "\u001b[1m Option 2: -------------------------------------- \u001b[0m \n",
      "\n",
      "regressor__min_samples_split: 10\n",
      "regressor__min_samples_leaf: 3\n",
      "regressor__min_impurity_decrease: 0.001\n",
      "regressor__max_features: sqrt\n",
      "regressor__max_depth: 20\n",
      "regressor__criterion: absolute_error\n",
      "\n",
      "    mean_train_R2  mean_train_MAE  mean_train_MAPE  mean_train_MedAE  \\\n",
      "4       0.910809      -1355.3979        -0.081502           -689.35   \n",
      "\n",
      "   mean_train_RMSE  mean_test_R2  mean_test_MAE  mean_test_MAPE  \\\n",
      "4     -2907.815093      0.869619   -1824.381912       -0.109647   \n",
      "\n",
      "   mean_test_MedAE  mean_test_RMSE  \n",
      "4         -1014.15    -3509.522262  \n"
     ]
    }
   ],
   "source": [
    "metric_cols = ['mean_train_R2', 'mean_train_MAE', 'mean_train_MAPE', 'mean_train_MedAE', 'mean_train_RMSE',\n",
    "    'mean_test_R2' , 'mean_test_MAE', 'mean_test_MAPE', 'mean_test_MedAE', 'mean_test_RMSE']\n",
    "\n",
    "for i, row in enumerate([0,4]):\n",
    "    print (f'\\n{'\\033[1m'} Option {i+1}: -------------------------------------- {'\\033[0m'} \\n')\n",
    "\n",
    "    params = df_metrics.loc[row, 'params']\n",
    "    for key, value in params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    print('\\n', df_metrics.loc[[row], metric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "101d5517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RandomizedSearchCV with Pipeline...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "RandomizedSearchCV Results:\n",
      "Best parameters: {'regressor__min_samples_split': 10, 'regressor__min_samples_leaf': 3, 'regressor__min_impurity_decrease': 0.001, 'regressor__max_features': 'sqrt', 'regressor__max_depth': 20, 'regressor__criterion': 'absolute_error'}\n",
      "Best CV score: -1918.2721\n"
     ]
    }
   ],
   "source": [
    "print(\"Running RandomizedSearchCV with Pipeline...\")\n",
    "random_search3.fit(X, y)\n",
    "\n",
    "print(\"\\nRandomizedSearchCV Results:\")\n",
    "print(f\"Best parameters: {random_search3.best_params_}\")\n",
    "print(f\"Best CV score: {random_search3.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acb663b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_df3 = pd.DataFrame(random_search3.cv_results_)\n",
    "\n",
    "metric_cols_train3 = [c for c in results_df3.columns if c.startswith(\"mean_train_\")]\n",
    "std_cols_train3 = [c for c in results_df3.columns if c.startswith(\"std_train_\")]\n",
    "\n",
    "metric_cols_test3 = [c for c in results_df3.columns if c.startswith(\"mean_test_\")]\n",
    "std_cols_test3 = [c for c in results_df3.columns if c.startswith(\"std_test_\")]\n",
    "\n",
    "df_metrics3 = results_df3[[\"params\"] + metric_cols_train3 + std_cols_train3 + metric_cols_test3 + std_cols_test3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "593adc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_R2</th>\n",
       "      <th>mean_train_MAE</th>\n",
       "      <th>mean_train_MAPE</th>\n",
       "      <th>mean_train_MedAE</th>\n",
       "      <th>mean_train_RMSE</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>mean_test_MAE</th>\n",
       "      <th>mean_test_MAPE</th>\n",
       "      <th>mean_test_MedAE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'regressor__min_samples_split': 3, 'regressor...</td>\n",
       "      <td>0.910334</td>\n",
       "      <td>-1556.111357</td>\n",
       "      <td>-0.095654</td>\n",
       "      <td>-909.015791</td>\n",
       "      <td>-2914.742393</td>\n",
       "      <td>0.862471</td>\n",
       "      <td>-1953.598388</td>\n",
       "      <td>-0.120190</td>\n",
       "      <td>-1140.289048</td>\n",
       "      <td>-3609.462336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'regressor__min_samples_split': 10, 'regresso...</td>\n",
       "      <td>0.452810</td>\n",
       "      <td>-4294.695712</td>\n",
       "      <td>-0.284254</td>\n",
       "      <td>-2703.250000</td>\n",
       "      <td>-7192.663048</td>\n",
       "      <td>0.448412</td>\n",
       "      <td>-4318.754308</td>\n",
       "      <td>-0.287252</td>\n",
       "      <td>-2722.000000</td>\n",
       "      <td>-7224.579582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'regressor__min_samples_split': 10, 'regresso...</td>\n",
       "      <td>0.374018</td>\n",
       "      <td>-4812.966141</td>\n",
       "      <td>-0.327320</td>\n",
       "      <td>-3174.400000</td>\n",
       "      <td>-7703.353694</td>\n",
       "      <td>0.369892</td>\n",
       "      <td>-4838.779406</td>\n",
       "      <td>-0.329457</td>\n",
       "      <td>-3210.200000</td>\n",
       "      <td>-7728.422202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'regressor__min_samples_split': 20, 'regresso...</td>\n",
       "      <td>0.374018</td>\n",
       "      <td>-4812.966141</td>\n",
       "      <td>-0.327320</td>\n",
       "      <td>-3174.400000</td>\n",
       "      <td>-7703.353694</td>\n",
       "      <td>0.369892</td>\n",
       "      <td>-4838.779406</td>\n",
       "      <td>-0.329457</td>\n",
       "      <td>-3210.200000</td>\n",
       "      <td>-7728.422202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'regressor__min_samples_split': 10, 'regresso...</td>\n",
       "      <td>0.928421</td>\n",
       "      <td>-1141.035598</td>\n",
       "      <td>-0.069551</td>\n",
       "      <td>-505.000000</td>\n",
       "      <td>-2603.766006</td>\n",
       "      <td>0.855378</td>\n",
       "      <td>-1918.272063</td>\n",
       "      <td>-0.116859</td>\n",
       "      <td>-1035.600000</td>\n",
       "      <td>-3697.664048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'regressor__min_samples_split': 5, 'regressor...</td>\n",
       "      <td>0.777450</td>\n",
       "      <td>-2908.033762</td>\n",
       "      <td>-0.192256</td>\n",
       "      <td>-2054.263375</td>\n",
       "      <td>-4593.222925</td>\n",
       "      <td>0.773311</td>\n",
       "      <td>-2930.549275</td>\n",
       "      <td>-0.193724</td>\n",
       "      <td>-2062.996567</td>\n",
       "      <td>-4634.359606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'regressor__min_samples_split': 10, 'regresso...</td>\n",
       "      <td>0.833656</td>\n",
       "      <td>-2430.755645</td>\n",
       "      <td>-0.159051</td>\n",
       "      <td>-1586.540193</td>\n",
       "      <td>-3968.735325</td>\n",
       "      <td>0.796668</td>\n",
       "      <td>-2608.074824</td>\n",
       "      <td>-0.169581</td>\n",
       "      <td>-1668.578424</td>\n",
       "      <td>-4389.080177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'regressor__min_samples_split': 10, 'regresso...</td>\n",
       "      <td>0.446853</td>\n",
       "      <td>-4325.296811</td>\n",
       "      <td>-0.285015</td>\n",
       "      <td>-2735.300000</td>\n",
       "      <td>-7230.304599</td>\n",
       "      <td>0.442965</td>\n",
       "      <td>-4343.209023</td>\n",
       "      <td>-0.286876</td>\n",
       "      <td>-2737.000000</td>\n",
       "      <td>-7258.946937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'regressor__min_samples_split': 10, 'regresso...</td>\n",
       "      <td>0.454722</td>\n",
       "      <td>-4739.889510</td>\n",
       "      <td>-0.335177</td>\n",
       "      <td>-3474.328810</td>\n",
       "      <td>-7186.861985</td>\n",
       "      <td>0.448548</td>\n",
       "      <td>-4751.031080</td>\n",
       "      <td>-0.336770</td>\n",
       "      <td>-3477.523725</td>\n",
       "      <td>-7228.565857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'regressor__min_samples_split': 10, 'regresso...</td>\n",
       "      <td>0.834963</td>\n",
       "      <td>-2201.649422</td>\n",
       "      <td>-0.135648</td>\n",
       "      <td>-1326.750000</td>\n",
       "      <td>-3953.178731</td>\n",
       "      <td>0.818870</td>\n",
       "      <td>-2349.221259</td>\n",
       "      <td>-0.145475</td>\n",
       "      <td>-1457.300000</td>\n",
       "      <td>-4142.315792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_train_R2  \\\n",
       "0  {'regressor__min_samples_split': 3, 'regressor...       0.910334   \n",
       "1  {'regressor__min_samples_split': 10, 'regresso...       0.452810   \n",
       "2  {'regressor__min_samples_split': 10, 'regresso...       0.374018   \n",
       "3  {'regressor__min_samples_split': 20, 'regresso...       0.374018   \n",
       "4  {'regressor__min_samples_split': 10, 'regresso...       0.928421   \n",
       "5  {'regressor__min_samples_split': 5, 'regressor...       0.777450   \n",
       "6  {'regressor__min_samples_split': 10, 'regresso...       0.833656   \n",
       "7  {'regressor__min_samples_split': 10, 'regresso...       0.446853   \n",
       "8  {'regressor__min_samples_split': 10, 'regresso...       0.454722   \n",
       "9  {'regressor__min_samples_split': 10, 'regresso...       0.834963   \n",
       "\n",
       "   mean_train_MAE  mean_train_MAPE  mean_train_MedAE  mean_train_RMSE  \\\n",
       "0    -1556.111357        -0.095654       -909.015791     -2914.742393   \n",
       "1    -4294.695712        -0.284254      -2703.250000     -7192.663048   \n",
       "2    -4812.966141        -0.327320      -3174.400000     -7703.353694   \n",
       "3    -4812.966141        -0.327320      -3174.400000     -7703.353694   \n",
       "4    -1141.035598        -0.069551       -505.000000     -2603.766006   \n",
       "5    -2908.033762        -0.192256      -2054.263375     -4593.222925   \n",
       "6    -2430.755645        -0.159051      -1586.540193     -3968.735325   \n",
       "7    -4325.296811        -0.285015      -2735.300000     -7230.304599   \n",
       "8    -4739.889510        -0.335177      -3474.328810     -7186.861985   \n",
       "9    -2201.649422        -0.135648      -1326.750000     -3953.178731   \n",
       "\n",
       "   mean_test_R2  mean_test_MAE  mean_test_MAPE  mean_test_MedAE  \\\n",
       "0      0.862471   -1953.598388       -0.120190     -1140.289048   \n",
       "1      0.448412   -4318.754308       -0.287252     -2722.000000   \n",
       "2      0.369892   -4838.779406       -0.329457     -3210.200000   \n",
       "3      0.369892   -4838.779406       -0.329457     -3210.200000   \n",
       "4      0.855378   -1918.272063       -0.116859     -1035.600000   \n",
       "5      0.773311   -2930.549275       -0.193724     -2062.996567   \n",
       "6      0.796668   -2608.074824       -0.169581     -1668.578424   \n",
       "7      0.442965   -4343.209023       -0.286876     -2737.000000   \n",
       "8      0.448548   -4751.031080       -0.336770     -3477.523725   \n",
       "9      0.818870   -2349.221259       -0.145475     -1457.300000   \n",
       "\n",
       "   mean_test_RMSE  \n",
       "0    -3609.462336  \n",
       "1    -7224.579582  \n",
       "2    -7728.422202  \n",
       "3    -7728.422202  \n",
       "4    -3697.664048  \n",
       "5    -4634.359606  \n",
       "6    -4389.080177  \n",
       "7    -7258.946937  \n",
       "8    -7228.565857  \n",
       "9    -4142.315792  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_metrics3[['params',\n",
    "            'mean_train_R2', 'mean_train_MAE', 'mean_train_MAPE', 'mean_train_MedAE', 'mean_train_RMSE',\n",
    "            'mean_test_R2', 'mean_test_MAE', 'mean_test_MAPE', 'mean_test_MedAE', 'mean_test_RMSE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e9dfb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m Option 1: -------------------------------------- \u001b[0m \n",
      "\n",
      "regressor__min_samples_split: 3\n",
      "regressor__min_samples_leaf: 10\n",
      "regressor__min_impurity_decrease: 0.0001\n",
      "regressor__max_features: sqrt\n",
      "regressor__max_depth: None\n",
      "regressor__criterion: squared_error\n",
      "\n",
      "    mean_train_R2  mean_train_MAE  mean_train_MAPE  mean_train_MedAE  \\\n",
      "0       0.910334    -1556.111357        -0.095654       -909.015791   \n",
      "\n",
      "   mean_train_RMSE  mean_test_R2  mean_test_MAE  mean_test_MAPE  \\\n",
      "0     -2914.742393      0.862471   -1953.598388        -0.12019   \n",
      "\n",
      "   mean_test_MedAE  mean_test_RMSE  \n",
      "0     -1140.289048    -3609.462336  \n",
      "\n",
      "\u001b[1m Option 2: -------------------------------------- \u001b[0m \n",
      "\n",
      "regressor__min_samples_split: 10\n",
      "regressor__min_samples_leaf: 3\n",
      "regressor__min_impurity_decrease: 0.001\n",
      "regressor__max_features: sqrt\n",
      "regressor__max_depth: 20\n",
      "regressor__criterion: absolute_error\n",
      "\n",
      "    mean_train_R2  mean_train_MAE  mean_train_MAPE  mean_train_MedAE  \\\n",
      "4       0.928421    -1141.035598        -0.069551            -505.0   \n",
      "\n",
      "   mean_train_RMSE  mean_test_R2  mean_test_MAE  mean_test_MAPE  \\\n",
      "4     -2603.766006      0.855378   -1918.272063       -0.116859   \n",
      "\n",
      "   mean_test_MedAE  mean_test_RMSE  \n",
      "4          -1035.6    -3697.664048  \n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate([0,4]):\n",
    "    print (f'\\n{'\\033[1m'} Option {i+1}: -------------------------------------- {'\\033[0m'} \\n')\n",
    "\n",
    "    params = df_metrics3.loc[row, 'params']\n",
    "    for key, value in params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    print('\\n', df_metrics3.loc[[row], metric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b465d2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m Option 1: -------------------------------------- \u001b[0m \n",
      "\n",
      "With Feature Selection only:\n",
      "\n",
      "regressor__min_samples_split: 3\n",
      "regressor__min_samples_leaf: 10\n",
      "regressor__min_impurity_decrease: 0.0001\n",
      "regressor__max_features: sqrt\n",
      "regressor__max_depth: None\n",
      "regressor__criterion: squared_error\n",
      "\n",
      "With Feature Selection and PCA:\n",
      "\n",
      "regressor__min_samples_split: 3\n",
      "regressor__min_samples_leaf: 10\n",
      "regressor__min_impurity_decrease: 0.0001\n",
      "regressor__max_features: sqrt\n",
      "regressor__max_depth: None\n",
      "regressor__criterion: squared_error\n",
      "\n",
      "\u001b[1m Option 2: -------------------------------------- \u001b[0m \n",
      "\n",
      "With Feature Selection only:\n",
      "\n",
      "regressor__min_samples_split: 10\n",
      "regressor__min_samples_leaf: 3\n",
      "regressor__min_impurity_decrease: 0.001\n",
      "regressor__max_features: sqrt\n",
      "regressor__max_depth: 20\n",
      "regressor__criterion: absolute_error\n",
      "\n",
      "With Feature Selection and PCA:\n",
      "\n",
      "regressor__min_samples_split: 10\n",
      "regressor__min_samples_leaf: 3\n",
      "regressor__min_impurity_decrease: 0.001\n",
      "regressor__max_features: sqrt\n",
      "regressor__max_depth: 20\n",
      "regressor__criterion: absolute_error\n"
     ]
    }
   ],
   "source": [
    "rows_to_concat = [\n",
    "    df_metrics.loc[[0], metric_cols],   # opção 1 de df_metrics\n",
    "    df_metrics3.loc[[0], metric_cols],  # opção 1 de df_metrics3\n",
    "    df_metrics.loc[[4], metric_cols],   # opção 2 de df_metrics\n",
    "    df_metrics3.loc[[4], metric_cols]   # opção 2 de df_metrics3\n",
    "]\n",
    "\n",
    "for i, row in enumerate([0,4]):\n",
    "    print (f'\\n{'\\033[1m'} Option {i+1}: -------------------------------------- {'\\033[0m'} \\n')\n",
    "\n",
    "    print('With Feature Selection only:\\n')\n",
    "    params = df_metrics.loc[row, 'params']\n",
    "    for key, value in params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    print('\\nWith Feature Selection and PCA:\\n')\n",
    "    params = df_metrics3.loc[row, 'params']\n",
    "    for key, value in params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "comparison_df = pd.concat(rows_to_concat, ignore_index=True)\n",
    "comparison_df.index= ['FS_Option1', 'FS_PCA_Option1', 'FS_Option2', 'FS_PCA_Option2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31fa853c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_R2</th>\n",
       "      <th>mean_train_MAE</th>\n",
       "      <th>mean_train_MAPE</th>\n",
       "      <th>mean_train_MedAE</th>\n",
       "      <th>mean_train_RMSE</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>mean_test_MAE</th>\n",
       "      <th>mean_test_MAPE</th>\n",
       "      <th>mean_test_MedAE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FS_Option1</th>\n",
       "      <td>0.899829</td>\n",
       "      <td>-1687.418622</td>\n",
       "      <td>-0.102923</td>\n",
       "      <td>-1011.809827</td>\n",
       "      <td>-3081.312867</td>\n",
       "      <td>0.873194</td>\n",
       "      <td>-1894.056494</td>\n",
       "      <td>-0.115705</td>\n",
       "      <td>-1133.045593</td>\n",
       "      <td>-3463.051823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS_PCA_Option1</th>\n",
       "      <td>0.910334</td>\n",
       "      <td>-1556.111357</td>\n",
       "      <td>-0.095654</td>\n",
       "      <td>-909.015791</td>\n",
       "      <td>-2914.742393</td>\n",
       "      <td>0.862471</td>\n",
       "      <td>-1953.598388</td>\n",
       "      <td>-0.120190</td>\n",
       "      <td>-1140.289048</td>\n",
       "      <td>-3609.462336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS_Option2</th>\n",
       "      <td>0.910809</td>\n",
       "      <td>-1355.397900</td>\n",
       "      <td>-0.081502</td>\n",
       "      <td>-689.350000</td>\n",
       "      <td>-2907.815093</td>\n",
       "      <td>0.869619</td>\n",
       "      <td>-1824.381912</td>\n",
       "      <td>-0.109647</td>\n",
       "      <td>-1014.150000</td>\n",
       "      <td>-3509.522262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS_PCA_Option2</th>\n",
       "      <td>0.928421</td>\n",
       "      <td>-1141.035598</td>\n",
       "      <td>-0.069551</td>\n",
       "      <td>-505.000000</td>\n",
       "      <td>-2603.766006</td>\n",
       "      <td>0.855378</td>\n",
       "      <td>-1918.272063</td>\n",
       "      <td>-0.116859</td>\n",
       "      <td>-1035.600000</td>\n",
       "      <td>-3697.664048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean_train_R2  mean_train_MAE  mean_train_MAPE  \\\n",
       "FS_Option1           0.899829    -1687.418622        -0.102923   \n",
       "FS_PCA_Option1       0.910334    -1556.111357        -0.095654   \n",
       "FS_Option2           0.910809    -1355.397900        -0.081502   \n",
       "FS_PCA_Option2       0.928421    -1141.035598        -0.069551   \n",
       "\n",
       "                mean_train_MedAE  mean_train_RMSE  mean_test_R2  \\\n",
       "FS_Option1          -1011.809827     -3081.312867      0.873194   \n",
       "FS_PCA_Option1       -909.015791     -2914.742393      0.862471   \n",
       "FS_Option2           -689.350000     -2907.815093      0.869619   \n",
       "FS_PCA_Option2       -505.000000     -2603.766006      0.855378   \n",
       "\n",
       "                mean_test_MAE  mean_test_MAPE  mean_test_MedAE  mean_test_RMSE  \n",
       "FS_Option1       -1894.056494       -0.115705     -1133.045593    -3463.051823  \n",
       "FS_PCA_Option1   -1953.598388       -0.120190     -1140.289048    -3609.462336  \n",
       "FS_Option2       -1824.381912       -0.109647     -1014.150000    -3509.522262  \n",
       "FS_PCA_Option2   -1918.272063       -0.116859     -1035.600000    -3697.664048  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d216eac",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef140f7",
   "metadata": {},
   "source": [
    "Usar separadamente (sem ter corrido random search) (isto foi só para dar debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aafda770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical_Correction works\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>mileage</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "      <th>paintQuality%</th>\n",
       "      <th>previousOwners</th>\n",
       "      <th>hasDamage</th>\n",
       "      <th>Brand_cleaned</th>\n",
       "      <th>transmission_cleaned</th>\n",
       "      <th>fuelType_cleaned</th>\n",
       "      <th>model_cleaned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69512</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>28421.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VW</td>\n",
       "      <td>SEMI-AUTO</td>\n",
       "      <td>PETROL</td>\n",
       "      <td>GOLF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53000</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>4589.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>47.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>PETROL</td>\n",
       "      <td>YARIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6366</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>3624.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>40.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AUDI</td>\n",
       "      <td>SEMI-AUTO</td>\n",
       "      <td>PETROL</td>\n",
       "      <td>Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29021</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>9102.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FORD</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>PETROL</td>\n",
       "      <td>FIESTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10062</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMW</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>PETROL</td>\n",
       "      <td>2 SERIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37194</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>14480.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>53.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MERCEDES</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>PETROL</td>\n",
       "      <td>C CLASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>52134.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>47.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AUDI</td>\n",
       "      <td>SEMI-AUTO</td>\n",
       "      <td>DIESEL</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>11304.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>AUTOMATIC</td>\n",
       "      <td>PETROL</td>\n",
       "      <td>AYGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>69072.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>60.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AUDI</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>DIESEL</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>16709.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>64.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FORD</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>PETROL</td>\n",
       "      <td>FIESTA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75973 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  mileage    tax   mpg  engineSize  paintQuality%  \\\n",
       "carID                                                            \n",
       "69512  2016.0  28421.0    NaN   NaN         2.0           63.0   \n",
       "53000  2019.0   4589.0  145.0  47.9         1.5           50.0   \n",
       "6366   2019.0   3624.0  145.0  40.9         1.5           56.0   \n",
       "29021  2018.0   9102.0  145.0  65.7         1.0           50.0   \n",
       "10062  2019.0   1000.0  145.0  42.8         1.5           97.0   \n",
       "...       ...      ...    ...   ...         ...            ...   \n",
       "37194  2015.0  14480.0  125.0  53.3         2.0           78.0   \n",
       "6265   2013.0  52134.0  200.0  47.9         2.0           38.0   \n",
       "54886  2017.0  11304.0  145.0  67.0         1.0           57.0   \n",
       "860    2015.0  69072.0  125.0  60.1         2.0           74.0   \n",
       "15795  2018.0  16709.0  145.0  64.2         1.1           38.0   \n",
       "\n",
       "       previousOwners  hasDamage Brand_cleaned transmission_cleaned  \\\n",
       "carID                                                                 \n",
       "69512             4.0        0.0            VW            SEMI-AUTO   \n",
       "53000             1.0        0.0        TOYOTA               MANUAL   \n",
       "6366              4.0        0.0          AUDI            SEMI-AUTO   \n",
       "29021             NaN        0.0          FORD               MANUAL   \n",
       "10062             3.0        0.0           BMW               MANUAL   \n",
       "...               ...        ...           ...                  ...   \n",
       "37194             0.0        0.0      MERCEDES               MANUAL   \n",
       "6265              2.0        0.0          AUDI            SEMI-AUTO   \n",
       "54886             3.0        0.0        TOYOTA            AUTOMATIC   \n",
       "860               2.0        0.0          AUDI               MANUAL   \n",
       "15795             1.0        0.0          FORD               MANUAL   \n",
       "\n",
       "      fuelType_cleaned model_cleaned  \n",
       "carID                                 \n",
       "69512           PETROL          GOLF  \n",
       "53000           PETROL         YARIS  \n",
       "6366            PETROL            Q2  \n",
       "29021           PETROL        FIESTA  \n",
       "10062           PETROL      2 SERIES  \n",
       "...                ...           ...  \n",
       "37194           PETROL       C CLASS  \n",
       "6265            DIESEL            Q3  \n",
       "54886           PETROL          AYGO  \n",
       "860             DIESEL            Q3  \n",
       "15795           PETROL        FIESTA  \n",
       "\n",
       "[75973 rows x 12 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Categorical_Correction\n",
    "cat_corrector = Categorical_Correction()\n",
    "X = cat_corrector.fit_transform(X)\n",
    "print(\"Categorical_Correction works\")\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a042692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Treatment works\n"
     ]
    }
   ],
   "source": [
    "# Outlier_Treatment\n",
    "outlier = Outlier_Treatment()\n",
    "X = outlier.fit_transform(X)\n",
    "print(\"Outlier Treatment works\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0934f433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "numeric_features = ['year', 'tax', 'mileage', 'previousOwners', 'engineSize', 'paintQuality%', 'mpg']\n",
    "\n",
    "fig, axes = plt.subplots(ceil(len(numeric_features) / 3 ), 3, figsize = (18,10))\n",
    "\n",
    "\n",
    "for ax, feat in zip(axes.flatten(), numeric_features):\n",
    "    sns.boxplot(x=X[feat], ax=ax, color='skyblue')\n",
    "\n",
    "# Delete empty plots\n",
    "for ax in axes.flatten()[len(numeric_features):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(\"Numerical Variables' Box Plots\", fontsize=25)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b45b29cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Treatment works\n"
     ]
    }
   ],
   "source": [
    "# Missing_Value_Treatment\n",
    "missing = Missing_Value_Treatment()\n",
    "X = missing.fit_transform(X)\n",
    "print(\"Missing Treatment works\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed654e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typecasting works\n"
     ]
    }
   ],
   "source": [
    "# Typecasting\n",
    "type = Typecasting()\n",
    "X = type.fit_transform(X)\n",
    "print(\"Typecasting works\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "122310fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Eng works\n"
     ]
    }
   ],
   "source": [
    "# Test Feature_Engineering\n",
    "feature_eng = Feature_Engineering()\n",
    "X = feature_eng.fit_transform(X,y)\n",
    "print(\"Feature Eng works\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c1233dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                    0\n",
       "mileage                 0\n",
       "tax                     0\n",
       "mpg                     0\n",
       "engineSize              0\n",
       "paintQuality%           0\n",
       "previousOwners          0\n",
       "hasDamage               0\n",
       "Brand_cleaned           0\n",
       "transmission_cleaned    0\n",
       "fuelType_cleaned        0\n",
       "model_cleaned           0\n",
       "carAge                  0\n",
       "AvgUsage                0\n",
       "carSegment              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4237539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder works\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "code = Encoder()\n",
    "X = code.fit_transform(X,y)\n",
    "print(\"Encoder works\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58b1b751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler works\n"
     ]
    }
   ],
   "source": [
    "# Scaler\n",
    "scaler = Scaler()\n",
    "X = scaler.fit_transform(X,y)\n",
    "print(\"Scaler works\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8167c265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'mileage', 'tax', 'mpg', 'engineSize', 'paintQuality%',\n",
       "       'previousOwners', 'hasDamage', 'carAge', 'AvgUsage', 'carSegment',\n",
       "       'model_cleaned_encoded', 'Brand_cleaned_encoded',\n",
       "       'fuelType_cleaned_DIESEL', 'fuelType_cleaned_ELECTRIC',\n",
       "       'fuelType_cleaned_HYBRID', 'fuelType_cleaned_OTHER',\n",
       "       'fuelType_cleaned_PETROL', 'transmission_cleaned_AUTOMATIC',\n",
       "       'transmission_cleaned_MANUAL', 'transmission_cleaned_OTHER',\n",
       "       'transmission_cleaned_SEMI-AUTO', 'transmission_cleaned_UNKNOWN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e5cb92e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feat Selection works\n"
     ]
    }
   ],
   "source": [
    "# Test Categorical_Correction\n",
    "selection = Feature_Selection()\n",
    "X = selection.fit_transform(X,y)\n",
    "print(\"Feat Selection works\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31b577df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'mileage', 'tax', 'mpg', 'engineSize', 'carAge', 'AvgUsage',\n",
       "       'carSegment', 'model_cleaned_encoded', 'Brand_cleaned_encoded',\n",
       "       'fuelType_cleaned_DIESEL', 'fuelType_cleaned_PETROL',\n",
       "       'transmission_cleaned_MANUAL', 'transmission_cleaned_SEMI-AUTO',\n",
       "       'fuelType_cleaned_ELECTRIC', 'fuelType_cleaned_OTHER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
